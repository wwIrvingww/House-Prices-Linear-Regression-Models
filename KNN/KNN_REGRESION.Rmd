---
title: "KNN_REGRESION"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

```{r cargando paquetes, message=FALSE, warning=FALSE}
library(GGally)
library(dplyr)
library(tidyverse)
library(class)
library(ggplot2)
library(caret)
```


```{r load_data, include=FALSE}
#train data ya tiene el 70 y test_data el 30%
train_data <- read.csv("train_final.csv")
test_data <- read.csv("test_final.csv")
```

```{r remove_na_columns}
porcentaje_na <- sapply(train_data, function(x) sum(is.na(x)) / length(x)) * 100

columnas_a_eliminar <- names(porcentaje_na[porcentaje_na > 75])
print(columnas_a_eliminar)

train_data <- train_data[, !names(train_data) %in% columnas_a_eliminar]
test_data <- test_data[, !names(test_data) %in% columnas_a_eliminar]
```

```{r divide_and_process_empty}}
numeric_columns <- train_data %>% select(where(is.numeric)) %>% names ()
categorical_columns <- train_data %>% select(where(~ !is.numeric(.))) %>% names()

preProc_num_train <- preProcess(train_data[, numeric_columns], method = "medianImpute")
preProc_num_test <- preProcess(test_data[, numeric_columns], method = "medianImpute")

train_data[, numeric_columns] <- predict(preProc_num_train, train_data[, numeric_columns])
test_data[, numeric_columns] <- predict(preProc_num_test, test_data[, numeric_columns])


niveles_por_columna <- sapply(test_data[, categorical_columns], function(x) length(unique(x)))
# Mostrar las columnas con un solo nivel (me dio un error antes con la funcion del encoder)
columnas_con_un_solo_nivel <- names(niveles_por_columna[niveles_por_columna == 1])
print("Columnas con un solo nivel:")
print(columnas_con_un_solo_nivel)

# Eliminar columnas con un solo nivel
train_data <- train_data[, !names(train_data) %in% columnas_con_un_solo_nivel]
test_data <- test_data[, !names(test_data) %in% columnas_con_un_solo_nivel]

# Actualizar
categorical_columns <- train_data %>% select(where(~ !is.numeric(.))) %>% names()

```

```{r combine_num_cat}
# Crear un encoder para las variables categóricas
encoder <- dummyVars("~ .", data = train_data[, categorical_columns], fullRank = FALSE)

# Aplicar el encoder a los datos de entrenamiento y prueba
train_categorical_encoded <- as.data.frame(predict(encoder, newdata = train_data[, categorical_columns]))
test_categorical_encoded <- as.data.frame(predict(encoder, newdata = test_data[, categorical_columns]))

# Verificar si faltan columnas en test_categorical_encoded
columnas_faltantes <- setdiff(names(train_categorical_encoded), names(test_categorical_encoded))

# Agregar las columnas faltantes a test_categorical_encoded con valores 0
for (col in columnas_faltantes) {
  test_categorical_encoded[[col]] <- 0
}

# Reordenar las columnas de test_categorical_encoded para que coincidan con train_categorical_encoded
test_categorical_encoded <- test_categorical_encoded[, names(train_categorical_encoded)]

# data ya con encoded y datos jutnados
train_encoded <- cbind(train_data[, numeric_columns], train_categorical_encoded)
test_encoded <- cbind(test_data[, numeric_columns], test_categorical_encoded)


# Imputar valores faltantes en las columnas numéricas con la media
for (i in 1:ncol(train_encoded)) {
  if (is.numeric(train_encoded[, i])) {  # Solo aplicamos a columnas numéricas
    train_encoded[is.na(train_encoded[, i]), i] <- mean(train_encoded[, i], na.rm = TRUE)
  }
}

for (i in 1:ncol(test_encoded)) {
  if (is.numeric(test_encoded[, i])) {  # Solo aplicamos a columnas numéricas
    test_encoded[is.na(test_encoded[, i]), i] <- mean(test_encoded[, i], na.rm = TRUE)
  }
}

# Verificar valores faltantes en los datos de entrenamiento y prueba
#colSums(is.na(train_encoded))
#colSums(is.na(test_encoded))

# Verificar valores faltantes en los datos
print("Valores faltantes en train_encoded:")
print(colSums(is.na(train_encoded)))
print("Variables que estan en train")
print(ncol(train_encoded))

print("Valores faltantes en test_encoded:")
print(colSums(is.na(test_encoded)))
print("Variables que estan en test")
print(ncol(test_encoded))

```


## 1.Elabore un modelo de regresión usando K nearest Neighbors (KNN), el conjunto de entrenamiento y la variable respuesta SalesPrice. Prediga con el modelo y explique los resultados a los que llega. Asegúrese que los conjuntos de entrenamiento y prueba sean los mismos de las entregas anteriores para que los modelos sean comparables.

```{r training}}
set.seed(123)


# Definir el valor de k a mano
k_vecinos <- round(sqrt(nrow(train_encoded)), 0)

parametros <- expand.grid(k = k_vecinos)

# entranmiento (en el ejemplo en canvas se hacía el training de una forma similar pero esta me parcio apropiada tambie, ya que se excluye completamente la variable respuesta del data set)
modelo_knn <- train(
  SalePrice~.,  
  data = train_encoded,        
  method = "knn",     
  preProcess = c("center", "scale"),  # Normalización
  tuneGrid = parametros  # Valor de k
)

# Mostrar el modelo entrenado
print("Este es el modelo resultante con los datos del training")
print(modelo_knn)
```


Con el print lo que vemos es el entrenamiento con el set de datos al que llamamos train_encoded. Este resultado ya muestra un MAE y un RMSE auqneu aún no hayamos hecho las predicciones. Pero por el método de aprendizaje KNN y la función que utilizamos de la librería CARET esta automáticamente hace una evaluación interna del modelo. Obteniendo como resultados:

* RMSE: 47063.15  
* Rsquared: 0.7098627
* MAE: 28763.05

```{r predict_testing}
print("Ahora aqui ya es donde se realiza la prediccion usando el set de datos de test")
predicciones <- predict(modelo_knn, newdata = test_encoded)
```

## 2.Analice los resultados del modelo de regresión usando KNN. ¿Qué tan bien le fue prediciendo? Utilice las métricas correctas.

```{r evaluating_prediction}}
# Crear el dataframe de resultados
df_resultados <- data.frame(
  Índice = 1:length(test_encoded$SalePrice),  # Índice de cada observación
  Real = test_encoded$SalePrice,              # Valores reales
  Predicho = predicciones                     # Valores predichos
)

# Graficar ambas series
ggplot(df_resultados) +
  geom_point(aes(x = Índice, y = Real, color = "Real"), size = 2) +  # Puntos rojos (valores reales)
  geom_point(aes(x = Índice, y = Predicho, color = "Predicho"), size = 2) +  # Puntos azules (predicciones)
  scale_color_manual(values = c("Real" = "red", "Predicho" = "blue")) +  # Definir colores
  labs(
    title = "Comparación: Valores Reales vs. Predicciones",
    x = "Índice de Observación",
    y = "Precio de la Casa (SalePrice)",
    color = "Serie"
  ) +
  theme_minimal()

# Calcular métricas de evaluación
rmse <- sqrt(mean((df_resultados$Real - df_resultados$Predicho)^2))
print(paste("RMSE:", rmse))

media_real <- mean(df_resultados$Real)

rmse_porcentual <- (rmse / media_real)

# Mostrar el RMSE porcentual
print(paste("RMSE porcentual:", rmse_porcentual))

rsquared <- cor(df_resultados$Real, df_resultados$Predicho)^2
print(paste("R²:", rsquared))

```

Viendo estos resultados de predicciones sobre el conjunto de testing podemos notar distintas cosas interesantes. Lo primero es en la gráfica donde se ven las diferencias entre el valor real y su correpondiente predicción. Se puede ver que cuando el precio de la casa es muy alto o muy bajo, al modelo se le dificulta realmente acercarse al valor real, la desviación de la predicción mayor es en esas partes. Mientras que en el centro y un poco abajo del centro se ve que los valores predichos (azules), se encuentran más cerca de los valores reales. 

Con respecto al RMSE los resultados son regulares, se tiene un R^2 de 77.98% y RMSE de 44760.89, osea casi $45K dolares de diferencia en el precio de una cas, lo cuál si representa una diferencia significativa en el contexto que se está analizando, el precio de una casa.Si lo vemos como un porcentaje para entender la seriedad del errror colocamos también la desviación del predicción como un porcentaje. La predicción se desvía un 24.68% aproximadamente, casi 1/4 del precio, por lo que el modelo no es tan bueno. Es importante mencionar que para este primer modelod eregresión se tomaron todas las varaibles del data set al igual que en otros modelos hechos anteriormente.

# 3

# 4

# 5 

