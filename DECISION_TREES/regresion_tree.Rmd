---
title: "regresion_tree"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(ggplot2)
library(GGally)
library(nortest)
library(dplyr)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
library(discretization)
```

```{r load_data, include=FALSE}
train_dataTree <- read_csv("train_final.csv")
test_dataTree <- read.csv("test_final.csv")
```

```{r remove_na_columns, include=FALSE}
porcentaje_na <- sapply(train_dataTree, function(x) sum(is.na(x)) / length(x)) * 100

columnas_a_eliminar <- names(porcentaje_na[porcentaje_na > 75])
print(columnas_a_eliminar)

train_dataTree <- train_dataTree[, !names(train_dataTree) %in% columnas_a_eliminar]
test_dataTree <- test_dataTree[, !names(test_dataTree) %in% columnas_a_eliminar]
```

# Arbol de regresion con todas las variables 
En este caso no es necesario hacer split nuevamente ya que el archivo train_final.csv ya tiene el 70% de los datos. El archivo test_final.csv tienen el 30%. Solo es necesario convertir el data frame de respuesta en 2 separados, uno que contenga la respuesta y otro que no.

```{r all_variables, echo=FALSE}

test_resp <- test_dataTree$SalePrice
test_dataTree$SalePrice <- NULL

train_dataTree<-train_dataTree %>% mutate_if(is.character,as.factor)
test_dataTree<-test_dataTree %>% mutate_if(is.character,as.factor)

arbol1 <- rpart(SalePrice~., data = train_dataTree)
rpart.plot(arbol1)
```

Con este primer modelo se puede observar cuales son las variables que se consideraron más importantes para la separación de datos. Siendo overallQual la característica principal par ala clasificacion. Anteriormente, en el análisis con regresión lineal, al analizar las variables logramos llegar a la misma conclusión. Aunque en aquel entonces fue considerablemente más complicado. En este caso con casi el mismo o menor procesamiento de datos se logran ver las variables relevantes para la clasificación incluyendo las categóricas (no numéricas).

```{r model1_no_params, echo=FALSE}
# Asegurar que las variables categóricas de test_dataTree tengan los mismos niveles que en train_dataTree
# ya que los datos se hicieron spli antes de hacer factor esto es necesario

for (col in names(train_dataTree)) {
  if (is.factor(train_dataTree[[col]])) {
    # Verificar si la columna existe en test_dataTree
    if (col %in% names(test_dataTree)) {
      test_dataTree[[col]] <- factor(test_dataTree[[col]], levels = levels(train_dataTree[[col]]))
    }
  }
}

predModelo1 <- predict(arbol1, newdata = test_dataTree)
rmseModelo1test<-RMSE(predModelo1,test_resp)

rmseModelo1test

# desviacion pero en porcentaje.
rmse_porcentaje <- (rmseModelo1test / mean(test_resp)) 
rmse_porcentaje

plot(test_resp, col="blue", main="Predicciones vs Valores originales")
points(predModelo1, col="red")
legend(30,45,legend=c("original","prediccion"), col=c("blue", "red"), pch=1,cex = 0.8)

```
Luego de obtener el el valor de RMSE y el valor en porcentaje, podemos ver que el modelo al predecir se desvía `r rmseModelo1test` del valor real. Este es un error considerablemente grande, tomando en cuenta que es el precio de la casa, dicha cantidad representa una diferencia significativa en el precio de una casa. El modelo en general se desvía un `r rmse_porcentaje`. Además de esto, al ver el gráfico aunque sean varios datos se nota la desviación de los valores predichos(rojo), con los valores reales(azul) 
Observando el gráfico nos damos cuenta que realmente. Por lo que el modelo seguramente puede ser mejorado, ya que en este primer intento se colocaron valores predeterminados y todas las variables del set de datos. 

```{r three_more_models}
# Modelo 2: Profundidad máxima = 2
arbol2 <- rpart(SalePrice ~ ., data = train_dataTree, control = rpart.control(maxdepth = 2))
rpart.plot(arbol2)
predModelo2 <- predict(arbol2, newdata = test_dataTree)
rmseModelo2test <- RMSE(predModelo2, test_resp)
rmse_porcentaje2 <- (rmseModelo2test / mean(test_resp))

# Modelo 3: Profundidad máxima = 7
arbol3 <- rpart(SalePrice ~ ., data = train_dataTree, control = rpart.control(maxdepth = 7))
rpart.plot(arbol3)
predModelo3 <- predict(arbol3, newdata = test_dataTree)
rmseModelo3test <- RMSE(predModelo3, test_resp)
rmse_porcentaje3 <- (rmseModelo3test / mean(test_resp))

# Modelo 4: Profundidad máxima = 10
arbol4 <- rpart(SalePrice ~ ., data = train_dataTree, control = rpart.control(maxdepth = 10))
rpart.plot(arbol4)
predModelo4 <- predict(arbol4, newdata = test_dataTree)
rmseModelo4test <- RMSE(predModelo4, test_resp)
rmse_porcentaje4 <- (rmseModelo4test / mean(test_resp))

# Comparar los RMSE de los modelos
resultados <- data.frame(
  Modelo = c("Modelo 1 (default)", "Modelo 2 (maxdepth=3)", "Modelo 3 (maxdepth=5)", "Modelo 4 (maxdepth=10)"),
  RMSE = c(rmseModelo1test, rmseModelo2test, rmseModelo3test, rmseModelo4test),
  RMSE_Porcentaje = c(rmse_porcentaje, rmse_porcentaje2, rmse_porcentaje3, rmse_porcentaje4)
)

resultados
```

```{r ploting3_results, echo=FALSE}
# Modelo 2
plot(test_resp, col = "blue", main = "Predicciones vs Valores originales (Modelo 2)")
points(predModelo2, col = "red")
legend("topleft", legend = c("Original", "Predicción"), col = c("blue", "red"), pch = 1, cex = 0.8)

# Modelo 3
plot(test_resp, col = "blue", main = "Predicciones vs Valores originales (Modelo 3)")
points(predModelo3, col = "red")
legend("topleft", legend = c("Original", "Predicción"), col = c("blue", "red"), pch = 1, cex = 0.8)

# Modelo 4
plot(test_resp, col = "blue", main = "Predicciones vs Valores originales (Modelo 4)")
points(predModelo4, col = "red")
legend("topleft", legend = c("Original", "Predicción"), col = c("blue", "red"), pch = 1, cex = 0.8)

```