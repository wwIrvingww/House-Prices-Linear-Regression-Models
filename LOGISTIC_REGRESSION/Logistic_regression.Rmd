---
title: "Logistic_regression"
author: "Irving, Chuy"
date: "2025-04-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(car)
library(reshape2)
library(ggplot2)
```

2.Use los mismos conjuntos de entrenamiento y prueba que utilizó en las hojas anteriores.
```{r load_data, include=FALSE}
#train data ya tiene el 70 y test_data el 30%
train_data <- read.csv("../train_final.csv")
test_data <- read.csv("../test_final.csv")
```
Se  cargó la data que se ha usado en entregas anteriores.

```{r remove_columns, include=FALSE}
train_data <- train_data %>% select(-Condition2, -RoofMatl, -Exterior2nd, -Electrical)
test_data <- test_data %>% select(-Condition2, -RoofMatl, -Exterior2nd, -Electrical)
```

```{r remove_na_columns, include=FALSE}
pct_na <- sapply(train_data, function(x) mean(is.na(x))*100)
drop_cols <- names(pct_na[pct_na > 75])
train_data <- train_data %>% select(-all_of(drop_cols))
test_data  <- test_data  %>% select(-all_of(drop_cols))
```
Se remueven las columnas que no dan información útil.

```{r discretization, include=FALSE}
breaks <- quantile(train_data$SalePrice, probs = c(0,1/3,2/3,1), na.rm=TRUE)
labels <- c("barata","estandar","cara")

train_data$CategoriaPrecio <- cut(train_data$SalePrice, breaks=breaks, labels=labels, include.lowest=TRUE)
test_data$CategoriaPrecio  <- cut(test_data$SalePrice,  breaks=breaks, labels=labels, include.lowest=TRUE)

```
Creamos las tres categorías de las casas (barata, estándar, cara.)

1. Cree una variable dicotómica por cada una de las categorías de la variable respuesta categórica que creó en hojas anteriores. Debería tener 3 variables dicotómicas (valores 0 y 1) una que diga si la vivienda es cara o no, media o no, económica o no.
```{r dicotomic_variable, echo=FALSE}
# Para el conjunto de entrenamiento
train_data <- train_data %>%
  mutate(
    Cara = ifelse(CategoriaPrecio == "cara", 1, 0),
    Estandar = ifelse(CategoriaPrecio == "estandar", 1, 0),
    Economica = ifelse(CategoriaPrecio == "barata", 1, 0)
  )

# Para el conjunto de prueba
test_data <- test_data %>%
  mutate(
    Cara = ifelse(CategoriaPrecio == "cara", 1, 0),
    Estandar = ifelse(CategoriaPrecio == "estandar", 1, 0),
    Economica = ifelse(CategoriaPrecio == "barata", 1, 0)
  )
```
Se crearon las tres variables dicotómicas para las categorías `barata`, `estandar` y `cara`

3. Elabore un modelo de regresión logística para conocer si una vivienda es cara o no, utilizando el conjunto
de entrenamiento y explique los resultados a los que llega. El experimento debe ser reproducible por lo
que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el
código. Use validación cruzada.

```{r process_data, echo=FALSE}
# 1. Selección de variables numéricas
numeric_cols <- train_data %>% select(where(is.numeric)) %>% names()

# 2. Selección de variables categóricas
all_cat <- train_data %>% select(where(~!is.numeric(.))) %>% names()
valid_cat <- all_cat[
  sapply(all_cat, function(col) {
    n_distinct(train_data[[col]]) > 1 && n_distinct(test_data[[col]]) > 1
  })
]

# 3. Imputación de valores perdidos en variables numéricas usando la mediana
preNum <- preProcess(train_data[numeric_cols], method = "medianImpute")
train_data[numeric_cols] <- predict(preNum, train_data[numeric_cols])
test_data[numeric_cols]  <- predict(preNum, test_data[numeric_cols])

# 4. Codificación (one-hot encoding) de variables categóricas
encoder <- dummyVars(~ ., data = train_data[valid_cat], fullRank = TRUE)
train_cat <- predict(encoder, train_data[valid_cat]) %>% as.data.frame()
test_cat  <- predict(encoder, test_data[valid_cat]) %>% as.data.frame()

# 5. Asegurarse que las columnas codificadas en el conjunto de prueba sean idénticas a las del entrenamiento
missing <- setdiff(names(train_cat), names(test_cat))
if(length(missing) > 0){
  test_cat[missing] <- 0
  test_cat <- test_cat[names(train_cat)]
}

# 6. Unir las variables numéricas procesadas, las variables dummy y la variable respuesta
train_encoded <- bind_cols(train_data[numeric_cols], train_cat, 
                           CategoriaPrecio = train_data$CategoriaPrecio)
test_encoded  <- bind_cols(test_data[numeric_cols],  test_cat,  
                           CategoriaPrecio = test_data$CategoriaPrecio)

```
Antes de elaborar el modelo, se realizó un procesamiento de la data para que sea compatible con el modelo que vamos a utilizar. Ya que el modelo no puede contener NAN's y el número de observaciones que contenía NAN's era menor a 100, se optó por omitir esas filas.



```{r logistic_regression, echo=FALSE}
# Fijamos la semilla para que la selección (y validación) sea reproducible
set.seed(1234)

# Preparamos el dataset para el modelado:
# Eliminamos variables que no queremos usar como predictoras:
# - SalePrice: la variable original numérica a partir de la cual se creó la variable objetivo.
# - CategoriaPrecio: la categorización original.
# - Estandar y Economica: las otras dos variables dicotómicas que derivamos.
# Así, nos quedamos con las variables predictoras y el target "Cara".
model_data <- train_data %>% select(-SalePrice, -CategoriaPrecio, -Estandar, -Economica)

# Eliminamos las filas que contienen valores perdidos
model_data <- na.omit(model_data)

# Configuramos la validación cruzada con 10 folds:
train_control <- trainControl(method = "cv", number = 10)

# Entrenamos el modelo de regresión logística usando caret.
# Se utiliza la familia binomial para indicar que se trata de un modelo logístico.
logistic_model <- train(as.factor(Cara) ~ ., 
                        data = model_data, 
                        method = "glm", 
                        family = "binomial", 
                        trControl = train_control)

# Mostramos el resumen del modelo
print(logistic_model)


```
El primer aspecto a notar es el aviso proporiconado por la librería," glm.fit: algorithm did not converge":
Esto indica que el algoritmo iterativo usado para ajustar la regresión logística no alcanzó la convergencia completa. En otras palabras, después de varias iteraciones, el método no pudo encontrar un conjunto de parámetros estables. Esto puede suceder cuando: Existen variables altamente correlacionadas (multicolinealidad), hay una separación completa o casi completa de las clases en algunos predictores. El siguiente aviso a tomarle importancia es"prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases":, este mensaje sugiere que el modelo es rank-deficient; es decir, hay redundancias entre las variables predictoras, de forma que algunos coeficientes no se pueden estimar de manera única. Esto suele suceder cuando existen variables con alta correlación o cuando se incluyen más predictores de los que la información en la muestra puede soportar.  
Ahora bien, hablando directamente de las estadísticas se obtuvo un `accurracy` de 0.7345955 y un `kappa` de 0.4682196 lo que sugiere que, a pesar de los avisos, el modelo tiene un desempeño moderado para clasificar las viviendas como "cara" (o no). Aunque el rendimiento predictivo es aceptable, los avisos indican que se debe ser cauteloso al interpretar los coeficientes y confiar en la estabilidad del modelo, por lo que se procederá a hacer un estadio más detallado para saber si hay multicolinealidad.

4. Analice el modelo. Determine si hay multicolinealidad en las variables, y cuáles son las que aportan al
modelo, por su valor de significación. Haga un análisis de correlación de las variables del modelo y
especifique si el modelo se adapta bien a los datos.

```{r modelo_summary, echo=TRUE}
# Ajustar un modelo de regresión logística usando el dataset 'model_data'
full_model <- glm(as.factor(Cara) ~ ., data = model_data, family = "binomial")

summary(full_model)
```

```{r definir_predictors_non_alias, echo=TRUE, warning=FALSE, message=FALSE}
# Extraer los nombres de los coeficientes del modelo original
coef_names <- names(coef(full_model))

# Identificar los coeficientes que NO están en la matriz de alias
aliased <- alias(full_model)$Complete
non_alias <- coef_names[!coef_names %in% rownames(aliased)]

# Excluir el intercepto
predictors_non_alias <- non_alias[non_alias != "(Intercept)"]

print("Predictors no aliasados:")
print(predictors_non_alias)
```

## este no corre
```{r settings_model, echo=TRUE}
# 1. Asegurarse de que 'predictors_non_alias' solo contenga los predictores que efectivamente están en model_data
available_predictors <- predictors_non_alias[predictors_non_alias %in% names(model_data)]
print("Predictores disponibles en model_data:")
print(available_predictors)

# 2. Envolver cada predictor disponible en backticks para que la fórmula sea sintácticamente válida
available_predictors_backticks <- paste0("`", available_predictors, "`")

# 3. Construir la fórmula utilizando únicamente los predictores disponibles
fmla_non_alias <- as.formula(paste("as.factor(Cara) ~", 
                                   paste(available_predictors_backticks, collapse = " + ")))
print("Fórmula del modelo sin predictores aliasados y con variables disponibles:")
print(fmla_non_alias)

# 4. Ajustar el modelo usando la fórmula corregida
full_model_non_alias <- glm(fmla_non_alias, data = model_data, family = "binomial")

# 5. Mostrar el resumen del nuevo modelo
summary(full_model_non_alias)


```

```{r vif_stimate, echo=TRUE}
# 1. Identificar los coeficientes aliasados (colineales) del modelo original
aliased <- alias(full_model)$Complete
print("Variables colineales (alias):")
print(aliased)

# 2. Extraer los nombres de los coeficientes del modelo original
coef_names <- names(coef(full_model))

# Identificar los coeficientes que NO están en la matriz de alias, es decir, que se pueden estimar
non_alias <- coef_names[!coef_names %in% rownames(aliased)]
print("Coeficientes no aliasados:")
print(non_alias)

# 3. Filtrar predictors_non_alias para obtener únicamente aquellos presentes en model_data
available_predictors <- predictors_non_alias[predictors_non_alias %in% names(model_data)]
print("Predictors no alias presentes en model_data:")
print(available_predictors)

# 4. Construir la fórmula usando únicamente los predictores disponibles (envolviéndolos en backticks)
available_predictors_backticks <- paste0("`", available_predictors, "`")
fmla_non_alias <- as.formula(paste("as.factor(Cara) ~", 
                                   paste(available_predictors_backticks, collapse = " + ")))
print("Fórmula del modelo sin predictores aliasados y solo con variables disponibles:")
print(fmla_non_alias)

# 5. Ajustar el nuevo modelo con la fórmula corregida
full_model_non_alias <- glm(fmla_non_alias, data = model_data, family = "binomial")

# 6. Calcular el VIF para el nuevo modelo utilizando la librería car
vif_values <- vif(full_model_non_alias)
print("Valores VIF para el modelo sin coeficientes aliasados:")
print(vif_values)

```
Al principio se mostró una  matriz con los alias del modelo original. Esto indica que, en el conjunto de predictores inicial, existen relaciones de dependencia lineal exacta entre algunas variables. Al filtrar estos predictores se crean modelos "no aliasados", es decir, solo se incluyen variables que se pueden estimar de forma única.  
Dentro de la función VIF se calcularon distintos valores de los cualees podemos discutir los siguiente:  
Variables como `Id` con 1.16 o `MSSubClass` con 1.59, `LotFrontage` 1.66, `LotArea` con 1.41 y algunos otros valores qque tiene un coeificiente entre 1 y 3. Esto indidca poca o ninguna colinealidad significativa en esos casos. Luego tenemos valores que son moderadamente altos como `X1stFlrSF` con 7.39 y `X2ndFlrSF` con 8.15, son valores altos de VIF. Las variables con estos valores, especialmente entre 5 y 10 están correlaciondas con otras. Por último tenemos variables con valores muy altos, por encima de 10, como `YearBuilt` con valores de aproximadamente 10.65 `GarageYrBlt` como `GarageYrBlt` 10.06, `BsmtFinSF1` con VIF de 9.58 y `BsmtUnfSF` y `8.62`. Estos valores indican que existe un problema de multicolinealidad fuerte en estos predictores. Sin embargo, está alta multicolinealidad es razonable en algunos casos, como que el año de construcción y el año de construcción del garaje se relacionen con la edad de la vivienda, y que las medidas de superficie del sótano estén altamente correlacionadas entre sí y posiblemente con la superficie del primer piso.  
En general aunque muchas de las variables tienen VIF razonablemente bajos, la presencia de algunos predictores con VIF superiores a 10 (o cercanos a esos valores) es una señal de que hay redundancia en la información, lo que podría volver inestables las estimaciones de los coeficientes y dificultar la interpretación individual de estos.


```{r correlacion_predictors_fixed, echo=TRUE, warning=FALSE, message=FALSE}
# Seleccionar únicamente las variables predictoras numéricas eliminando la variable respuesta "Cara"
predictors_numeric <- model_data %>% 
  select(-Cara) %>% 
  select(where(is.numeric))

# Calcular la matriz de correlación utilizando complete.obs
corr_matrix <- cor(predictors_numeric, use = "complete.obs")
print("Matriz de correlación (redondeada):")
print(round(corr_matrix, 2))
```
Al observar los valores de la matriz de correlación algunas variables de categoría como el tipo de construcción (`MSSubClass`) muestran correlaciones moderadas con otras medidas; por ejemplo, se observa una correlación negativa moderada (alrededor de –0.32) entre `MSSubClass` y `LotFrontage`, lo que podría sugerir que viviendas pertenecientes a ciertas categorías estructurales presentan diferencias en el frente de lote.  
Otro grupo de variables que destaca son las relacionadas con la calidad y la condición de la vivienda. En particular, “OverallQual” presenta correlaciones positivas notables con “YearBuilt” (0.53) y “YearRemodAdd” (0.57), lo que indica que a medida que las viviendas son más modernas o han sido remodeladas recientemente, tienden a tener calidades percibidas más altas.  
Las medidas de área constituyen otro bloque importante. Se observa que “TotalBsmtSF” y “X1stFlrSF” tienen una correlación muy alta (cercana a 0.90), lo cual sugiere que estas dos variables miden aspectos relacionados con el tamaño de la vivienda y que, en gran medida, se solapan en la información que aportan. Este tipo de correlación extremadamente alta es indicativa de redundancia, lo que a su vez contribuye a la multicolinealidad del modelo. De igual manera, otros indicadores de área, como “LotFrontage”, “LotArea” y “GrLivArea”, presentan correlaciones moderadas entre sí, lo que puede ser natural dado que todas miden dimensiones físicas del inmueble.  
Las variables temporales, “YearBuilt” y “YearRemodAdd”, muestran además una correlación alta (0.69), lo que sugiere que en muchas viviendas el año de construcción y el año de remodelación están estrechamente relacionados. Este patrón es común en muestras donde las remodelaciones suceden con mayor probabilidad en casas relativamente nuevas o donde hay una fuerte tendencia a actualizar la propiedad en un cierto rango de años.  
Entonces la matriz revela que aunque muchas variables presentan correlaciones moderadas o bajas existen agrupaciones de variables (particularmente las relacionadas con el tamaño y la estructura de la vivienda) que están fuertemente correlacionadas. Esto confirma la preocupación por la multicolinealidad que se detectó a través de los altos valores de VIF en ciertos predictores. 
La matriz de correlación respalda la presencia de redundancias en la información, especialmente entre variables de área y medidas temporales, lo que sugiere que una reducción de dimensiones o una selección cuidadosa de predictores podría mejorar la interpretabilidad del modelo sin comprometer sustancialmente su capacidad predictiva.  

```{r heatmap_correlacion, echo=FALSE, warning=FALSE, message=FALSE}


# Convertir la matriz de correlación en formato largo para facilitar la graficación
melted_corr <- melt(corr_matrix)

# Graficar la matriz de correlación utilizando un heatmap
ggplot(data = melted_corr, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       midpoint = 0, limit = c(-1, 1), name = "Correlación") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        axis.title = element_blank()) +
  labs(title = "Heatmap: Matriz de correlación de los predictores")
```
El heatmap de la matriz de correlación confirma de manera visual los hallazgos numéricos previos. Las áreas más intensamente coloreadas en rojo indican pares de variables con correlaciones positivas altas, mientras que los bloques en azul reflejan correlaciones negativas notables. En particular puede apreciarse un clúster de variables que representan la dimensión de la vivienda (por ejemplo, TotalBsmtSF, X1stFlrSF, GarageCars, GarageArea) mostrando altas correlaciones entre sí, lo que respalda la existencia de multicolinealidad detectada por los valores de VIF. De forma similar, otras zonas del mapa exhiben correlaciones elevadas entre las variables temporales (YearBuilt, YearRemodAdd, GarageYrBlt) y los indicadores de calidad (OverallQual, OverallCond). 

5. Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar.  
```{r model_test, echo=FALSE}
# Predecir las probabilidades para el conjunto de prueba usando el modelo ajustado (full_model_non_alias)
pred_probs <- predict(full_model_non_alias, newdata = test_data, type = "response")

# Convertir las probabilidades en clases (usamos un umbral de 0.5)
pred_class <- ifelse(pred_probs >= 0.5, 1, 0)

# Asegurarse que tanto las predicciones como la variable real de respuesta sean factores
pred_class <- as.factor(pred_class)
actual_class <- as.factor(test_data$Cara)

conf_mat <- confusionMatrix(pred_class, actual_class)
print(conf_mat)

```
La matriz de confusión y las estadísticas resultantes indican que el modelo de clasificación binaria (para predecir si una vivienda es "cara" o no) tiene un desempeño robusto. Con una **exactitud del 86.33%** y un intervalo de confianza del 95% entre 82.76% y 89.41%, el modelo supera significativamente la tasa de no información (66.06%), lo que se refleja en un p-valor muy bajo (< 2.2e-16) al comparar con la tasa de no información. Además, el valor de **Kappa (0.6806)** sugiere un acuerdo sustancial entre las predicciones y las observaciones reales, más allá de lo que se esperaría por azar.

En detalle, la **sensibilidad del 94.48%** (dado que la clase positiva se define como la etiqueta 0) indica que el modelo identifica correctamente la gran mayoría de las viviendas que pertenecen a la clase positiva. La **especificidad del 70.47%** evidencia que, aunque la identificación de la clase contraria (viviendas "cara", en este contexto) es moderada, el desempeño en general es bastante equilibrado, como lo refleja la **exactitud balanceada del 82.48%**. Los valores altos de las métricas de valor predictivo (Pos Pred Value: 86.16% y Neg Pred Value: 86.78%) refuerzan la idea de que el modelo es confiable al asignar correctamente la clase a nuevas observaciones.

Finalmente, el resultado del Test de McNemar (p-value = 0.0004909) indica que las discrepancias en los errores de clasificación son estadísticamente significativas, lo que añade evidencia a la robustez del modelo. En conjunto, estos resultados respaldan que el modelo tiene una capacidad predictiva sólida para discriminar entre viviendas clasificadas como "cara" y "no cara".

6. Explique si hay sobreajuste (overfitting) o no (recuerde usar para esto los errores del conjunto de prueba
y de entrenamiento). Muestre las curvas de aprendizaje usando los errores de los conjuntos de
entrenamiento y prueba

```{r}
# Diagnóstico de la causa del error "contrasts can be applied only to factors with 2 or more levels"

# 1. Analizar la variable de respuesta "Cara" en model_data completo
cat("Análisis de la variable de respuesta 'Cara' en model_data:\n")
cara_tabla <- table(model_data$Cara)
print(cara_tabla)
cat("Número de niveles en 'Cara':", length(unique(model_data$Cara)), "\n\n")

# 2. Revisar todas las variables de tipo factor en model_data y detectar las que tienen solo un nivel
cat("Análisis de variables de tipo factor en model_data:\n")
factor_vars <- sapply(model_data, is.factor)
if(any(factor_vars)) {
  # Iteramos sobre cada variable factor
  for (var in names(model_data)[factor_vars]) {
    num_levels <- length(unique(model_data[[var]]))
    if (num_levels < 2) {
      cat("La variable '", var, "' tiene únicamente ", num_levels, " nivel(es).\n", sep = "")
    }
  }
} else {
  cat("No se encontraron variables de tipo factor en model_data.\n")
}

cat("\n")

# 3. Diagnóstico en un subconjunto pequeño (10% de model_data) para ver si la selección de filas es la causa del error
set.seed(1234)
frac <- 0.1
subset_sample <- model_data[sample(nrow(model_data), size = floor(frac * nrow(model_data))), ]
cat("Análisis de la variable 'Cara' en un subconjunto (", frac*100, "% de model_data):\n", sep = "")
cara_subset_tabla <- table(subset_sample$Cara)
print(cara_subset_tabla)
if (length(unique(subset_sample$Cara)) < 2) {
  cat("El subconjunto tiene sólo una categoría en 'Cara'. Número de filas en el subconjunto:", nrow(subset_sample), "\n")
} else {
  cat("El subconjunto presenta ambas categorías en 'Cara'.\n")
}

```
```{r}
# 1. Función para preparar datos consistentes en el conjunto global
prepare_consistent_data <- function(train_df, test_df) {
  # Eliminar filas con NA en la variable respuesta
  train_df <- train_df %>% filter(!is.na(Cara))
  test_df <- test_df %>% filter(!is.na(Cara))
  
  # Eliminar columnas no relevantes
  cols_to_remove <- c("SalePrice", "CategoriaPrecio", "Estandar", "Economica")
  train_df <- train_df %>% select(-any_of(cols_to_remove))
  test_df <- test_df %>% select(-any_of(cols_to_remove))
  
  # Procesar variables categóricas: convertir a factor y eliminar si tienen solo un nivel
  cat_vars <- train_df %>% 
    select(where(~ is.character(.) | is.factor(.))) %>% 
    names()
  
  for (var in cat_vars) {
    train_df[[var]] <- as.factor(train_df[[var]])
    test_df[[var]] <- as.factor(test_df[[var]])
    
    if (nlevels(train_df[[var]]) < 2) {
      train_df <- train_df %>% select(-all_of(var))
      test_df <- test_df %>% select(-all_of(var))
      message("Variable eliminada por tener un solo nivel en train: ", var)
      next
    }
    
    # Para el conjunto global, eliminar filas en test que tengan niveles nuevos
    new_levels <- setdiff(levels(test_df[[var]]), levels(train_df[[var]]))
    if (length(new_levels) > 0) {
      message("Eliminando ", sum(test_df[[var]] %in% new_levels), 
              " filas de test con nuevos niveles en ", var, ": ", 
              paste(new_levels, collapse = ", "))
      test_df <- test_df %>% filter(!(.data[[var]] %in% new_levels))
    }
    
    # Forzar que test use los mismos niveles que train
    test_df[[var]] <- factor(test_df[[var]], levels = levels(train_df[[var]]))
  }
  
  # Eliminar columnas con muchos NA (>50%)
  pct_na <- sapply(train_df, function(x) mean(is.na(x)) * 100)
  high_na_cols <- names(pct_na[pct_na > 50])
  if (length(high_na_cols) > 0) {
    train_df <- train_df %>% select(-all_of(high_na_cols))
    test_df <- test_df %>% select(-all_of(high_na_cols))
    message("Variables con muchos NA eliminadas: ", paste(high_na_cols, collapse = ", "))
  }
  
  # Imputar medianas en variables numéricas (excepto la respuesta)
  num_vars <- train_df %>% select(where(is.numeric)) %>% names()
  num_vars <- setdiff(num_vars, "Cara")
  if (length(num_vars) > 0) {
    preProc <- preProcess(train_df[num_vars], method = "medianImpute")
    train_df[num_vars] <- predict(preProc, train_df[num_vars])
    test_df[num_vars] <- predict(preProc, test_df[num_vars])
  }
  
  # Convertir la variable respuesta a factor
  train_df$Cara <- as.factor(train_df$Cara)
  test_df$Cara <- as.factor(test_df$Cara)
  
  # Limpiar niveles no utilizados
  train_df <- droplevels(train_df)
  test_df <- droplevels(test_df)
  
  return(list(train = train_df, test = test_df))
}

# 2. Preparar los datos consistentes (global)
consistent_data <- prepare_consistent_data(train_data, test_data)
train_clean <- consistent_data$train
test_clean  <- consistent_data$test

# 3. Mostrar estructura final
message("\nDimensiones finales:")
message("Train: ", nrow(train_clean), " filas, ", ncol(train_clean), " columnas")
message("Test: ", nrow(test_clean), " filas, ", ncol(test_clean), " columnas")

# 4. Curvas de aprendizaje con validación robusta
set.seed(123)
train_sizes <- seq(0.1, 1, by = 0.1) * nrow(train_clean)
results <- data.frame()

for (size in train_sizes) {
  size <- round(size)
  # Seleccionar una muestra aleatoria del conjunto de entrenamiento global
  train_sub <- train_clean %>% sample_n(size)
  
  # Asegurarse de que las variables categóricas en train_sub reflejen los niveles actuales (eliminar niveles no usados)
  factor_vars <- names(train_sub)[sapply(train_sub, is.factor)]
  for (var in factor_vars) {
    train_sub[[var]] <- droplevels(train_sub[[var]])
  }
  
  # --- Eliminación de variables con nuevos niveles en test respecto a train_sub ---
  # Se comparan los niveles observados en el subconjunto de entrenamiento y
  # los niveles de test (tomando los valores actuales, no los niveles globales)
  invalid_vars <- c()
  for (var in factor_vars) {
    # Extrae los niveles efectivamente observados en train_sub para la variable
    observed_train <- levels(train_sub[[var]])
    # Extrae los valores presentes en test como caracteres y verifica si hay niveles no presentes en observed_train
    new_lvls <- setdiff(unique(as.character(test_clean[[var]])), observed_train)
    if (length(new_lvls) > 0) {
      invalid_vars <- c(invalid_vars, var)
    }
  }
  
  if (length(invalid_vars) > 0) {
    message("Eliminando variables por tener nuevos niveles: ", paste(invalid_vars, collapse = ", "))
    train_sub <- train_sub %>% select(-all_of(invalid_vars))
    test_valid <- test_clean %>% select(-all_of(invalid_vars))
  } else {
    test_valid <- test_clean
  }
  
  # Ajustar el modelo de regresión logística con el subconjunto modificado
  model <- tryCatch(
    {
      glm(Cara ~ ., data = train_sub, family = binomial)
    },
    error = function(e) {
      message("Error ajustando modelo para tamaño ", size, ": ", e$message)
      return(NULL)
    }
  )
  
  if (!is.null(model)) {
    # Obtener predicciones sobre el conjunto de entrenamiento y test_valid
    train_pred <- predict(model, train_sub, type = "response") > 0.5
    test_pred <- tryCatch(
      {
        predict(model, test_valid, type = "response") > 0.5
      },
      error = function(e) {
        message("Error en predicción para tamaño ", size, ": ", e$message)
        return(rep(NA, nrow(test_valid)))
      }
    )
    
    if (!any(is.na(test_pred))) {
      results <- rbind(results, data.frame(
        Train_Size = size,
        Train_Error = mean(train_pred != train_sub$Cara),
        Test_Error  = mean(test_pred != test_valid$Cara)
      ))
    }
  }
}

# 5. Graficar resultados si hay datos
if (nrow(results) > 0) {
  ggplot(results, aes(x = Train_Size)) +
    geom_line(aes(y = Train_Error, color = "Entrenamiento"), size = 1) +
    geom_line(aes(y = Test_Error, color = "Prueba"), size = 1) +
    labs(title = "Curvas de Aprendizaje - Modelo Final",
         subtitle = "Error vs Tamaño del Conjunto de Entrenamiento",
         x = "Tamaño de Entrenamiento",
         y = "Tasa de Error",
         color = "Conjunto") +
    scale_color_manual(values = c("Entrenamiento" = "blue", "Prueba" = "red")) +
    theme_minimal()
} else {
  message("No se pudieron calcular resultados debido a errores en el modelado")
}

# 6. Análisis final de sobreajuste
if (nrow(results) > 0) {
  final_errors <- tail(results, 1)
  message("\nResultados finales:")
  message("Error de entrenamiento: ", round(final_errors$Train_Error, 3))
  message("Error de prueba: ", round(final_errors$Test_Error, 3))
  
  diff_error <- final_errors$Test_Error - final_errors$Train_Error
  if (diff_error > 0.1) {
    message("\nADVERTENCIA: Posible sobreajuste (diferencia > 10%)")
  } else if (diff_error > 0.05) {
    message("\nAdvertencia leve: Ligero sobreajuste (diferencia > 5%)")
  } else {
    message("\nEl modelo parece generalizar bien (diferencia <= 5%)")
  }
}

```

```{r traingn}
# Fijamos semilla para reproducibilidad
set.seed(1234)

# Definir las fracciones del conjunto de entrenamiento a usar (del 10% al 100%)
fractions <- seq(0.1, 1, by = 0.1)
error_data <- data.frame(Fraction = fractions, Training_Error = NA, Test_Error = NA)

for (i in seq_along(fractions)) {
  frac <- fractions[i]
  
  # Obtener un subconjunto seguro del conjunto de entrenamiento
  sub_train <- get_safe_subset(model_data, frac, outcome_var = "Cara")
  
  # Si no se pudo obtener un subconjunto válido, se asignan NA a los errores
  if (is.null(sub_train)) {
    error_data$Training_Error[i] <- NA
    error_data$Test_Error[i] <- NA
    next
  }
  
  # Entrenar un modelo de regresión logística con el subconjunto
  model_sub <- glm(as.factor(Cara) ~ ., data = sub_train, family = "binomial")
  
  # Predecir en el subconjunto de entrenamiento
  preds_train <- predict(model_sub, newdata = sub_train, type = "response")
  pred_class_train <- ifelse(preds_train >= 0.5, 1, 0)
  # Convertir a numérico para poder comparar (asegurando la consistencia de niveles)
  train_error <- mean(pred_class_train != as.numeric(as.character(sub_train$Cara)))
  
  # Predecir en el conjunto de prueba
  preds_test <- predict(model_sub, newdata = test_data, type = "response")
  pred_class_test <- ifelse(preds_test >= 0.5, 1, 0)
  test_error <- mean(pred_class_test != as.numeric(as.character(test_data$Cara)))
  
  error_data$Training_Error[i] <- train_error
  error_data$Test_Error[i] <- test_error
}

print(error_data)

```

```{r graphics, echo=FALSE}
# Convertir error_data a formato largo para facilitar la graficación
library(reshape2)
error_data_long <- melt(error_data, id.vars = "Fraction", 
                        variable.name = "Dataset", 
                        value.name = "Error")

# Graficar las curvas de aprendizaje con ggplot2
library(ggplot2)
ggplot(error_data_long, aes(x = Fraction, y = Error, color = Dataset)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(title = "Curvas de Aprendizaje",
       subtitle = "Errores de entrenamiento y prueba según el tamaño del subconjunto de entrenamiento",
       x = "Proporción del conjunto de entrenamiento utilizada",
       y = "Error (proporción de clasificaciones incorrectas)") +
  theme_minimal()
```
