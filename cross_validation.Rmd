---
title: "Cross Validation"
author: "Irving, Chuy"
date: "2025-03-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Validación cruzada
A continuación se entrena un modelo con validación cruzada para después comparar su rendimiento con el arbol de decisión.

```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(caret)
library(readr)
library(dplyr)
library(forcats)
library(knitr)
```

```{r load_data, include=FALSE}
train_data <- read_csv("train_final.csv")
test_data <- read.csv("test_final.csv")

```

```{r prepare_data, include=FALSE}
numeric_columns <- train_data %>% select(where(is.numeric)) %>% names ()
categorical_columns <- train_data %>% select(where(is.character)) %>% names ()

preProc_num <- preProcess(train_data[, numeric_columns], method = "medianImpute")
train_data[, numeric_columns] <- predict(preProc_num, train_data[, numeric_columns])

for (col in categorical_columns) {
  moda <- names(sort(table(train_data[[col]]), decreasing = TRUE)) [1]
  train_data[[col]][is.na(train_data[[col]])] <- moda
}

na_summary <- colSums(is.na(train_data))

preProc <- preProcess(train_data, method = c("medianImpute"))
train_data <- predict(preProc, train_data)

```


## Validación cruzada para clasificacion
```{r cross_validation, echo=FALSE}
if (!"consumoCat" %in% colnames(train_data)) {
  categorias <- cut(train_data$SalePrice, 
                    breaks = c(min(train_data$SalePrice),
                               quantile(train_data$SalePrice, probs = 1/3),
                               quantile(train_data$SalePrice, probs = 2/3),
                               max(train_data$SalePrice)),
                    labels = c("barata", "estandar", "cara"),
                    include.lowest = TRUE)

  train_data$consumoCat <- categorias
}

train_data <- train_data %>% select(-SalePrice)

control <- trainControl(method = "cv", number = 5)

# Entrenar árbol de clasificación
set.seed(123)  # Reproducibilidad
modelo_clasificacion <- train(consumoCat ~ .,data = train_data, method = "rpart",trControl = control,metric = "Accuracy")

print(modelo_clasificacion)

rpart.plot(modelo_clasificacion$finalModel, main="Árbol de Clasificación con Validación Cruzada")

print(modelo_clasificacion$results)
```
Podemos observar como el mejor modelo fue el que tiene un cp de 0.44, pues su acurracy fie el más alto, alcanzando un valor de 0.6876, lo que nos indica un que el modelo clasifica correctamente (aprox) 7 de cada 10 casas, y un kappa de 0.53, este valor indica que es mejor a un clsificador aleatorio.  
Con respecto de del árbol de clasificación obervamos como de nuevo la variable que mejor clasifica por excelencia es `OverallQuall`. Si el valor de esta es menor a 7 entonces existe una mayor probabilidad de que pertenezca a un precio barato o estandar. Dentro de este subgrupo de OverallQual < 7 se introduce una división donde si OverallQual es menor a 6, existe una mayor tendencia a que sea barata, mientras que valores entre 6 y 7 sugieren la posibilidad de que sean estándar.  
Por otro lado, las viviendas con OverallQual mayor 7 se categorizan en su mayoría como caras.  
A simple vista podemos decir que el modelo de clasification de árbol posee un acurracy más alto, con un valor de 0.7563, por lo que podemos decir que tiene mejor desempeño que este modelo que es de validación cruzada.  

## Probando con diferentes profundidades
```{r antoher_profundity}
# Definir configuraciones de profundidad
depth_settings <- list(
  modelo1 = list(maxdepth = 4),
  modelo2 = list(maxdepth = 6),
  modelo3 = list(maxdepth = 8)
)

# Crear lista para almacenar los modelos
resultados <- list()

# Entrenar los modelos con diferentes profundidades
for (nombre in names(depth_settings)) {
  set.seed(123)
  modelo <- train(
    consumoCat ~ ., 
    data = train_data, 
    method = "rpart", 
    trControl = trainControl(method = "cv", number = 5),
    tuneLength = 10,  # Ajusta automáticamente cp probando 10 valores diferentes
    control = rpart.control(maxdepth = depth_settings[[nombre]]$maxdepth)
  )
  resultados[[nombre]] <- modelo
}

accuracy_results <- data.frame(
  Modelo = character(),
  Profundidad = numeric(),
  Accuracy = numeric(),
  stringsAsFactors = FALSE
)

for (nombre in names(resultados)) {
  profundidad <- depth_settings[[nombre]]$maxdepth
  accuracy <- max(resultados[[nombre]]$results$Accuracy)

  accuracy_results <- rbind(accuracy_results, data.frame(
    Modelo = nombre,
    Profundidad = profundidad,
    Accuracy = accuracy
  ))

  print(paste("Mostrando el árbol:", nombre, "- Profundidad:", profundidad))

  rpart.plot(resultados[[nombre]]$finalModel, main = paste("Árbol con", nombre, "\nProfundidad:", profundidad))
}

print(accuracy_results)
```
Al realizar las prueba de validación cruzada para distintos niveles de profundida en el árbol, observamos que entre la profundiad de 6 y 8 no encontramos diferencia alguna, lo que nos dice que 6 es el máximo de profundida significante. El valor del `acurracy` es de *0.7630*, el cual ha sido hasta ahora el nivel más alto que se ha obtenido. 

#Prueba de árbol de decisión pero ahora con random forest
```{r random_forest_clasification}
str(train_data)
train_data <- train_data %>% select(-c("Id"))

control <- trainControl(method = "cv", number = 5)

# Entrenar el modelo de Random Forest
set.seed(123) 
modelo_rf <- train(
  consumoCat ~ .,  # Formula: predecir consumoCat usando todas las demás columnas
  data = train_data,  
  method = "rf",  # Random Forest
  trControl = control,  
  metric = "Accuracy",  
  tuneLength = 5,
  ntree = 500
)

modelo_rf

# Ver la importancia de las variables
var_importance <- varImp(modelo_rf)
plot(var_importance, main = "Importancia de las variables en Random Forest", top = 20)

# Comparar con el accuracy del árbol de decisión
print(paste("Accuracy del árbol de decisión:", max(resultados$modelo3$results$Accuracy)))
print(paste("Accuracy de Random Forest:", max(modelo_rf$results$Accuracy)))

```

Como se puede observar al final este fue el mejor resultado de todos los modelos que fueron entrenados, superando incluso al algoritmo de regresión lineal y las clasificaciones realizadas anteriormente. Es incluso mejor que el random forest de regresion. Logrando un Accuracy de 83%, este algoritmo es mucho más pesado que los demás debido a que aparte de hacer tuning para la mejora de hiperparámetros, se están realizando una gran cantidad de árboles para poder determinar variables más importantes. Al tener muchos arboles (500 en este caso de prueba), lo que hace esto es haer muchas predicciones dentro del entrenamiento con los distintos arboles. Los árboles tienen bastante variabilidad, ya que el muestro involucra distintos procesos aleatorios, lo cuál nos garantiza una mayor generalización y menos overfitting (el cuál fue el problema que tuvimos con la regresión lineal). Además, en este caso la clasificación ayuda bastante a que el modelo pueda predecir sobre una variable discreta (categoría de la casa) en un lugar de una variable continua (el precio). Ya que se tienen definidos rangos es que el módelo busca la mayor coincidencia entre las predicciones de los distintos árboles. Esta discretización ayuda mucho a mejroar el desempeño y nos permitió un realizar un modelo con alto accuracy tomando en cuenta las variables más relevantes. Como se puede ver en la gráfica, las variables más importante coinciden con las que se analizaron tanto la regresión lineal como en el arbol de clasificación. Por lo que podemos concluir que el modelo entrenado es bastante preciso y generalizado.Otro indicador además de l accuracy es el kappa. Este resultó ser mucho mayor a 0.50 (0.75 al final), lo cuál indica que el módelo no solo predice aleatoriamente y que de hecho es mejor que una clasificación aleatoria.

