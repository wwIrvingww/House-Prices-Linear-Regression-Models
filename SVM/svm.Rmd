---
title: "SVM"
author: "Irving, Chuy"
date: "2025-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(visdat)
library(ggplot2)
library(dplyr)
```

1. Use los mismos conjuntos de entrenamiento y prueba de las hojas de trabajo pasadas para probar el algoritmo. 
```{r load_data, echo=FALSE}
#train data ya tiene el 70 y test_data el 30%
train_data <- read.csv("../train_final.csv")
test_data <- read.csv("../test_final.csv")
```

```{r remove_na_columns, echo=FALSE}
pct_na <- sapply(train_data, function(x) mean(is.na(x))*100)
drop_cols <- names(pct_na[pct_na > 75])
train_data <- train_data %>% select(-all_of(drop_cols))
test_data  <- test_data  %>% select(-all_of(drop_cols))
```
Se removieron las columnas problematicas. Se remueven las columnas que no dan información útil.

3. Use como variable respuesta la variable categórica que especifica si la casa es barata, media o cara.
```{r discretization, echo=FALSE}
breaks <- quantile(train_data$SalePrice, probs = c(0,1/3,2/3,1), na.rm=TRUE)
labels <- c("barata","estandar","cara")

train_data$CategoriaPrecio <- cut(train_data$SalePrice, breaks=breaks, labels=labels, include.lowest=TRUE)
test_data$CategoriaPrecio  <- cut(test_data$SalePrice,  breaks=breaks, labels=labels, include.lowest=TRUE)

```
Creamos las tres categorías de las casas (barata, estándar, cara.)

2. Explore los datos y explique las transformaciones que debe hacerle para generar un modelo de máquinas vectoriales de soporte.

```{r structure}
str(train_data)        # Tipos (numérico, factor, character)
summary(train_data)    # Estadísticos básicos
```
La tabla contiene 1 021 registros y 82 variables: numéricas, de texto y la respuesta categórica CategoriaPrecio con tres niveles (“barata”, “estandar”, “cara”). Hay varios huecos en columnas como 190 valores perdidos en LotFrontage, 58 en GarageYrBlt y algunos en MasVnrArea, lo que sugiere la necesidad de imputar o eliminar esos casos antes de entrenar la SVM. Además aparecen muchas variables de texto que habrá que transformar (por ejemplo, con one-hot encoding) y variables numéricas con rangos muy dispares, por lo que un escalado será indispensable.

```{r NAN_values}
colSums(is.na(train_data))  
visdat::vis_miss(train_data)

```
Las variables con mayor proporción de valores faltantes son PoolQC (1 017 de 1 021, es decir ~99 %), MiscFeature (979 faltantes, ~96 %) y Fence (829 faltantes, ~81 %), que corresponden a amenidades poco comunes (piscina, característica miscelánea, cerca) y cuya ausencia indica simplemente que la casa carece de dicho elemento. A continuación aparecen Alley con 963 NAs (~94 %), FireplaceQu con 486 (~48 %) y las tres columnas de garaje (GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond) con 58 faltantes (~6 %). También hay huecos en el sótano (BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2 con 25–26 faltantes) y en la mampostería (MasVnrType, MasVnrArea con 7 faltantes). El resto de las variables numéricas tiene muy pocos o ningún NA, salvo LotFrontage con 190 faltantes (~19 %), mientras que Electrical aparece con 1 valor perdido.

Este patrón sugiere que muchos NAs reflejan la ausencia de una característica (p. ej. no hay piscina ni callejón) y deberían tratarse como una categoría “None” o “Sin dato” más que imputarse con la media. 

```{r balance, echo=TRUE}
# 1. Frecuencias absolutas y relativas
freqs <- table(train_data$CategoriaPrecio)
print(freqs)
print(prop.table(freqs))

# 2. Gráfico de barras de la proporción de cada categoría
library(ggplot2)
ggplot(train_data, aes(x = CategoriaPrecio)) +
  geom_bar(aes(y = ..prop.., group = 1), fill = "steelblue") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "Balance de categorías de precio en train_data",
    x     = "Categoría de Precio",
    y     = "Porcentaje"
  ) +
  theme_minimal()

```
La proporción de cada categoría es de 33.4 % para “barata”, 33.9 % para “estandar” y 32.7 % para “cara”. El gráfico de barras con eje en porcentaje confirma visualmente esta uniformidad, pues las tres barras tienen alturas muy similares, lo que sugiere un balance de clases prácticamente equiparado.

```{r distribution}
numeric_vars <- names(train_data)[sapply(train_data, is.numeric)]
library(reshape2)
melt(train_data[, numeric_vars]) %>%
 ggplot(aes(x = value)) + 
 facet_wrap(~variable, scales = "free") +
 geom_histogram(bins = 30)
```
La mayoría de las variables numéricas muestran distribuciones fuertemente sesgadas a la derecha con colas largas: por ejemplo, `LotArea`, `GrLivArea` y `SalePrice` concentran gran parte de los casos en valores bajos–medios pero con algunos outliers muy elevados. Variables como `LotFrontage`, `BsmtFinSF1` o `TotalBsmtSF` también presentan este comportamiento, evidenciando que unas pocas viviendas tienen frentes de lote o sótanos excepcionalmente grandes.  

Por otra parte, varias columnas aparecen casi siempre en cero (porches, piscina, `LowQualFinSF`, `BsmtFinSF2`, `X3SsnPorch`, `MiscVal`), lo cual indica que la mayoría de las casas carecen de esas características. Otras, como `OverallQual`, `OverallCond`, `FullBath` o `GarageCars`, son **discretas y acotadas**, con barras muy concentradas en unos pocos valores enteros.

```{r boxplots_significativas, echo=TRUE}
library(dplyr)
library(tidyr)
library(ggplot2)

# 1) Lista de variables con p‑value < 0.05 en tu modelo
vars_sig <- c(
  "LotFrontage",
  "OverallQual",
  "OverallCond",
  "YearBuilt",
  "X1stFlrSF",
  "X2ndFlrSF"
)

# 2) Preparamos un data.frame largo
df_long <- train_data %>%
  select(CategoriaPrecio, all_of(vars_sig)) %>%
  pivot_longer(
    cols      = -CategoriaPrecio,
    names_to  = "variable",
    values_to = "valor"
  )

# 3) Un único ggplot con facet_wrap
ggplot(df_long, aes(x = CategoriaPrecio, y = valor)) +
  geom_boxplot(fill = "steelblue") +
  facet_wrap(~ variable, scales = "free_y", ncol = 2) +
  labs(
    title = "Boxplots de variables significativas por Categoría de Precio",
    x     = "Categoría de Precio",
    y     = "Valor"
  ) +
  theme_minimal()


```
En los boxplots de “LotFrontage”, “OverallQual” y “OverallCond” se observa una clara tendencia ascendente en la mediana al pasar de casas “baratas” a “estandar” y “cara”. Para LotFrontage, la mediana sube de aproximadamente 60 pies en “barata” a cerca de 70 pies en “cara”, con un rango intercuartílico que también se expande ligeramente y numerosos outliers hacia valores altos. En OverallQual, la calidad general crece de una mediana de 5 en “barata” a 7 en “cara”, reflejando que las viviendas más caras suelen tener calidades superiores. OverallCond muestra menos variabilidad, pero igualmente un ligero aumento de la mediana (cerca de 5 en “barata” y “estandar”, y ligeramente mayor en “cara”), aunque con outliers de bajas condiciones en las casas más económicas.

En los boxplots de “X1stFlrSF”, “X2ndFlrSF” y “YearBuilt” también se aprecian patrones consistentes. Para la superficie de planta baja (X1stFlrSF), la mediana crece de unos 900 ft² en “barata” a aproximadamente 1 400 ft^2 en “cara”, y el rango intercuartílico se ensancha, indicando casas más grandes en las categorías superiores. X2ndFlrSF es prácticamente nulo en “barata”, moderate en “estandar” (medianas cercanas a 500 ft^2) y mayor en “cara” (medianas de 600–700 ft^2), con outliers discrecionales hacia valores altos. Finalmente, *YearBuilt* revela que las casas “baratas” tienden a construirse antes de 1950 (mediana en torno a 1940), las “estandar” alrededor de 1970–1980, y las “cara” después de 1990, confirmando que las viviendas más nuevas están asociadas a precios más altos.


```{r correlation}
corr_mat <- cor(train_data[, numeric_vars], use = "pairwise.complete.obs")
corrplot::corrplot(corr_mat, tl.cex = .6)
caret::findCorrelation(corr_mat, cutoff = 0.9)  
```
En el mapa de correlaciones se aprecia un bloque de alta correlación positiva entre las variables de tamaño: `GrLivArea`, `X1stFlrSF` y `TotalBsmtSF` presentan coeficientes cercanos a 0.8–0.9 entre sí, lo que indica que las superficies de planta baja, sótano y área total están muy ligadas. De igual modo, `GarageCars` y `GarageArea` muestran un vínculo fuerte (≈0.85), así como `YearBuilt` y `YearRemodAdd` (≈0.7), reflejando que las remodelaciones suelen ocurrir poco después de la construcción original. Por otro lado, varias variables como `PoolArea`, `MiscVal`, `LowQualFinSF` exhiben correlaciones prácticamente nulas o muy bajas con el resto, quedando prácticamente aisladas en la matriz.

Fijándonos en la última fila/columna de `SalePrice`, las relaciones más destacadas son con `OverallQual` (≈0.8), `GrLivArea` (≈0.7), `X1stFlrSF` y `TotalBsmtSF` (≈0.6), y moderadas con `GarageCars`/`GarageArea` (0.6–0.65). También aparece una correlación razonable con `YearBuilt` (≈0.5), indicando que casas más nuevas suelen venderse más caras. Las variables climáticas o de fecha de venta (`MoSold`, `YrSold`) tienen correlaciones prácticamente cero con el precio, confirmando que el momento de la venta no sesga fuertemente el valor.

```{r ggpairs_significativas, echo=TRUE, message=FALSE, warning=FALSE}
library(GGally)
library(ggplot2)

# Seleccionamos las variables numéricas más significativas + la categórica
vars_sig <- c(
  "LotFrontage",
  "OverallQual",
  "OverallCond",
  "YearBuilt",
  "X1stFlrSF",
  "X2ndFlrSF",
  "CategoriaPrecio"
)

# Creamos el pair plot
ggpairs(
  train_data,
  columns = vars_sig,
  mapping = aes(color = CategoriaPrecio, alpha = 0.5),
  upper = list(continuous = wrap("cor", size = 3)),   # Correlaciones arriba
  lower = list(continuous = wrap("points", size = 0.5)), 
  diag  = list(continuous = "densityDiag")           # Densidad en la diagonal
) +
  theme_minimal() +
  labs(title = "Relaciones entre variables significativas y Categoría de Precio")

```
En los **paneles diagonales** de densidad se aprecia cómo las distribuciones de cada variable se desplazan progresivamente: para `LotFrontage` el pico de densidad rojo (barata) está alrededor de 55–60, el verde (estandar) cerca de 65–70 y el azul (cara) hacia 75–80; en `OverallQual` se ve un desplazamiento semejante de medianas de 5 a 7. Los **diagramas de dispersión** (parte inferior) muestran cómo las tres categorías se solapan pero avanzan en diagonal: casas “caras” (azul) tienden a combinar mayor calidad (`OverallQual`) con lotes y áreas más grandes (`LotFrontage`, `X1stFlrSF`, `X2ndFlrSF`), mientras que las “baratas” (rojo) quedan en la porción baja de cada nube.

En los **paneles superiores** se anotan los coeficientes de correlación global y por categoría. Por ejemplo, `X1stFlrSF` vs. `SalePrice` tiene una **correlación global** de 0.478, pero dentro de “estandar” es aún mayor (≈0.535) y más moderada en “cara” (≈0.233). `OverallQual` vs. `SalePrice` arroja 0.303 global, con “barata” en 0.274, “estandar” en 0.291 y “cara” en 0.019, reflejando que la fuerza de asociación varía según el segmento de precio. Varias relaciones (p. ej. `YearBuilt` vs. `SalePrice`) son débiles globalmente (≈0.146) y casi nulas en ciertos grupos, lo que señala heterogeneidad en la dinámica de cada categoría.

```{r nearZero_variance}
nzv <- caret::nearZeroVar(train_data, saveMetrics = TRUE)
nzv[nzv$nzv, ]

```
Cada variable marcada con `nzv = TRUE` (por ejemplo `Street`, `PoolArea`, `EnclosedPorch`, `Functional`, etc.) presenta muy poca variabilidad: una proporción altísima de casos en una sola categoría (freqRatio muy elevada) y casi ningún valor único (percentUnique muy bajo). En la práctica, esto significa que esas columnas no aportan separación útil entre clases y pueden introducir ruido o redundancia en el modelo.

Por ello, es recomendable **eliminar** todas las variables con `nzv = TRUE` antes de entrenar la SVM. Con esto reduces la dimensionalidad sin perder información relevante, aceleras el ajuste y evitas posibles problemas de sobreajuste o condicionamiento numérico.

```{r}
library(dplyr)
library(ggfortify)

# 1. Limpiar filas que tengan NA o Inf en las variables numéricas
df_pca <- train_data %>%
  select(all_of(numeric_vars), CategoriaPrecio) %>%
  filter(if_all(all_of(numeric_vars), ~ is.finite(.)))

# 2. Ajustar PCA con centrado y escalado estándar
pca_res <- prcomp(df_pca[, numeric_vars], center = TRUE, scale. = TRUE)

# 3. Graficar PCA coloreado por categoría de precio
autoplot(pca_res, data = df_pca, colour = "CategoriaPrecio") +
  theme_minimal() +
  labs(
    title = "PCA de Variables Numéricas",
    x     = "Primer Componente Principal (PC1)",
    y     = "Segundo Componente Principal (PC2)"
  )


```
En el diagrama de PCA, las tres categorías muestran un **gradient en el eje horizontal (PC1)**: las casas “cara” (azul) tienden a concentrarse hacia valores negativos de PC1, las “estandar” (verde) orbitan alrededor de cero, y las “barata” (rojo) se desplazan hacia valores positivos. Esto indica que la primera componente principal capta gran parte de la variabilidad asociada al precio, aunque existe un **solapamiento notable** entre categorías, por lo que no se genera una separación perfectamente lineal.

La **segunda componente (PC2)** añade un matiz vertical: algunos puntos de “cara” sobresalen en la parte alta del gráfico y algunas “barata” aparecen más abajo, revelando que PC2 recoge variaciones secundarias relacionadas con otras características numéricas. Aún así, la superposición persiste en ambas dimensiones, lo que sugiere que, si bien los dos primeros PCs explican gran parte de la variabilidad global, por sí solos no bastan para segmentar completamente las tres clases.