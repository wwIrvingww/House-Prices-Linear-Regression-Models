---
title: "SVM"
author: "Irving, Chuy"
date: "2025-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(visdat)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
library(GGally)
library(ggfortify)
library(caret)
```

1. Use los mismos conjuntos de entrenamiento y prueba de las hojas de trabajo pasadas para probar el algoritmo. 
```{r load_data, echo=FALSE}
#train data ya tiene el 70 y test_data el 30%
train_data <- read.csv("../train_final.csv")
test_data <- read.csv("../test_final.csv")
```

```{r remove_na_columns, echo=FALSE}
pct_na <- sapply(train_data, function(x) mean(is.na(x))*100)
drop_cols <- names(pct_na[pct_na > 75])
train_data <- train_data %>% select(-all_of(drop_cols))
test_data  <- test_data  %>% select(-all_of(drop_cols))
```
Se removieron las columnas problematicas. Se remueven las columnas que no dan información útil.

3. Use como variable respuesta la variable categórica que especifica si la casa es barata, media o cara.
```{r discretization, echo=FALSE}
breaks <- quantile(train_data$SalePrice, probs = c(0,1/3,2/3,1), na.rm=TRUE)
labels <- c("barata","estandar","cara")

train_data$CategoriaPrecio <- cut(train_data$SalePrice, breaks=breaks, labels=labels, include.lowest=TRUE)
test_data$CategoriaPrecio  <- cut(test_data$SalePrice,  breaks=breaks, labels=labels, include.lowest=TRUE)

```
Creamos las tres categorías de las casas (barata, estándar, cara.)

2. Explore los datos y explique las transformaciones que debe hacerle para generar un modelo de máquinas vectoriales de soporte.

```{r structure, echo=FALSE}
str(train_data)        # Tipos (numérico, factor, character)
summary(train_data)    # Estadísticos básicos
```
La tabla contiene 1 021 registros y 82 variables: numéricas, de texto y la respuesta categórica CategoriaPrecio con tres niveles (“barata”, “estandar”, “cara”). Hay varios huecos en columnas como 190 valores perdidos en LotFrontage, 58 en GarageYrBlt y algunos en MasVnrArea, lo que sugiere la necesidad de imputar o eliminar esos casos antes de entrenar la SVM. Además aparecen muchas variables de texto que habrá que transformar y variables numéricas con rangos muy dispares, por lo que un escalado será indispensable.

```{r NAN_values, echo=FALSE}
colSums(is.na(train_data))  
visdat::vis_miss(train_data)

```
Las variables con mayor proporción de valores faltantes son PoolQC (1 017 de 1 021, es decir ~99 %), MiscFeature (979 faltantes, ~96 %) y Fence (829 faltantes, ~81 %). También aparecen Alley con 963 NAs (~94 %), FireplaceQu con 486 (~48 %) y las tres columnas de garaje (GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond) con 58 faltantes (~6 %). También hay huecos en el sótano (BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2 con 25–26 faltantes) y en la mampostería (MasVnrType, MasVnrArea con 7 faltantes). El resto de las variables numéricas tiene muy pocos o ningún NA, salvo LotFrontage con 190 faltantes (~19 %), mientras que Electrical aparece con 1 valor perdido.

Este patrón sugiere que muchos NAs reflejan la ausencia de una característica (p. ej. no hay piscina ni callejón) y deberían tratarse como una categoría “None” o “Sin dato” más que imputarse con la media. 

```{r balance, echo=FALSE}
freqs <- table(train_data$CategoriaPrecio)
print(freqs)
print(prop.table(freqs))


ggplot(train_data, aes(x = CategoriaPrecio)) +
  geom_bar(aes(y = ..prop.., group = 1), fill = "steelblue") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "Balance",
    x     = "Categoría de Precio",
    y     = "Porcentaje"
  ) +
  theme_minimal()

```
La proporción de cada categoría es de 33.4 % para “barata”, 33.9 % para “estandar” y 32.7 % para “cara”. El gráfico de barras con eje en porcentaje confirma visualmente esta uniformidad, pues las tres barras tienen alturas muy similares, lo que sugiere un balance de clases prácticamente equiparado.

```{r distribution, echo=FALSE}
numeric_vars <- names(train_data)[sapply(train_data, is.numeric)]

melt(train_data[, numeric_vars]) %>%
 ggplot(aes(x = value)) + 
 facet_wrap(~variable, scales = "free") +
 geom_histogram(bins = 30)
```
La mayoría de las variables numéricas muestran distribuciones  sesgadas a la derecha con colas largas, por ejemplo: `LotArea`, `GrLivArea` y `SalePrice` concentran gran parte de los casos en valores bajos–medios pero con algunos outliers muy elevados. Variables como `LotFrontage`, `BsmtFinSF1` o `TotalBsmtSF` también presentan este comportamiento, evidenciando que unas pocas viviendas tienen frentes de lote o sótanos excepcionalmente grandes.  

Por otra parte, varias columnas aparecen casi siempre en cero (porches, piscina, `LowQualFinSF`, `BsmtFinSF2`, `X3SsnPorch`, `MiscVal`), lo cual indica que la mayoría de las casas carecen de esas características.

```{r boxplots, echo=FALSE}
vars_sig <- c(
  "LotFrontage",
  "OverallQual",
  "OverallCond",
  "YearBuilt",
  "X1stFlrSF",
  "X2ndFlrSF"
)

df_long <- train_data %>%
  select(CategoriaPrecio, all_of(vars_sig)) %>%
  pivot_longer(
    cols      = -CategoriaPrecio,
    names_to  = "variable",
    values_to = "valor"
  )

ggplot(df_long, aes(x = CategoriaPrecio, y = valor)) +
  geom_boxplot(fill = "steelblue") +
  facet_wrap(~ variable, scales = "free_y", ncol = 2) +
  labs(
    title = "Boxplots de variables significativas por Categoría de Precio",
    x     = "Categoría de Precio",
    y     = "Valor"
  ) +
  theme_minimal()


```
En los boxplots de *LotFrontage*, *OverallQual* y *OverallCond* se observa que la mediana tiende a aumentar conforme se pasa de viviendas categorizadas como *baratas* a *estándar* y luego a *caras*. En el caso específico de *LotFrontage*, la mediana sube aproximadamente de 60 pies en la categoría *barata* hasta cerca de 70 pies en la categoría *cara*, con un rango  que también se incrementa ligeramente y numerosos valores atípicos hacia la zona alta. Por otro lado, en *OverallQual* se aprecia cómo la calidad general aumenta desde una mediana de 5 en viviendas *baratas* hasta alcanzar un valor de 7 en las viviendas *caras*, reflejando que las casas más costosas suelen poseer una calidad superior. En contraste, *OverallCond* presenta menor variabilidad, aunque también se observa un ligero incremento de la mediana.  

Para **X1stFlrSF** la mediana aumenta desde aproximadamente 900 pies cuadrados en viviendas *baratas* hasta cerca de 1 400 pies cuadrados en las viviendas *caras*, acompañada por un rango  más amplio lo que indica que las viviendas de categorías superiores tienden a ser más grandes. En cuanto a **X2ndFlrSF** es casi inexistente en viviendas *baratas*, moderada en viviendas *estándar* (medianas alrededor de 500 pies cuadrados), y notablemente mayor en las viviendas *caras* (medianas entre 600 y 700 pies cuadrados), con algunos valores atípicos dispersos hacia valores aún más altos. Por último, *YearBuilt* revela que las viviendas clasificadas como *baratas* tienden a haber sido construidas antes de 1950, mientras que las *estándar* suelen ubicarse alrededor de las décadas de 1970 y 1980, y las *caras* después de 1990.

```{r correlation, echo=FALSE}
corr_mat <- cor(train_data[, numeric_vars], use = "pairwise.complete.obs")
corrplot::corrplot(corr_mat, tl.cex = .6)
caret::findCorrelation(corr_mat, cutoff = 0.9)  
```
En el mapa de correlaciones se aprecia un bloque de alta correlación positiva entre las variables de tamaño: `GrLivArea`, `X1stFlrSF` y `TotalBsmtSF` presentan coeficientes cercanos a 0.8–0.9 entre sí, lo que indica que las superficies de planta baja, sótano y área total están muy ligadas. De igual modo, `GarageCars` y `GarageArea` muestran un vínculo fuerte (≈0.85), así como `YearBuilt` y `YearRemodAdd` (≈0.7), reflejando que las remodelaciones suelen ocurrir poco después de la construcción original. Por otro lado, varias variables como `PoolArea`, `MiscVal`, `LowQualFinSF` exhiben correlaciones prácticamente nulas o muy bajas con el resto, quedando prácticamente aisladas en la matriz.

Fijándonos en la última fila/columna de `SalePrice`, las relaciones más destacadas son con `OverallQual` (≈0.8), `GrLivArea` (≈0.7), `X1stFlrSF` y `TotalBsmtSF` (≈0.6), y moderadas con `GarageCars`/`GarageArea` (0.6–0.65). También aparece una correlación razonable con `YearBuilt` (≈0.5), indicando que casas más nuevas suelen venderse más caras. Las variables climáticas o de fecha de venta (`MoSold`, `YrSold`) tienen correlaciones prácticamente cero con el precio, confirmando que el momento de la venta no sesga fuertemente el valor.

```{r ggpairs_significativas, echo=FALSE}

vars_sig <- c(
  "LotFrontage",
  "OverallQual",
  "OverallCond",
  "YearBuilt",
  "X1stFlrSF",
  "X2ndFlrSF",
  "CategoriaPrecio"
)

ggpairs(
  train_data,
  columns = vars_sig,
  mapping = aes(color = CategoriaPrecio, alpha = 0.5),
  upper = list(continuous = wrap("cor", size = 3)),
  lower = list(continuous = wrap("points", size = 0.5)), 
  diag  = list(continuous = "densityDiag")
) +
  theme_minimal() +
  labs(title = "Relaciones entre variables significativas y Categoría de Precio")

```
En los *paneles diagonales* de densidad se aprecia cómo las distribuciones de cada variable se desplazan progresivamente: para `LotFrontage` el pico de densidad rojo (barata) está alrededor de 55–60, el verde (estandar) cerca de 65–70 y el azul (cara) hacia 75–80; en `OverallQual` se ve un desplazamiento semejante de medianas de 5 a 7. Los *diagramas de dispersión* (parte inferior) muestran cómo las tres categorías se solapan pero avanzan en diagonal: casas “caras” (azul) tienden a combinar mayor calidad (`OverallQual`) con lotes y áreas más grandes (`LotFrontage`, `X1stFlrSF`, `X2ndFlrSF`), mientras que las “baratas” (rojo) quedan en la porción baja de cada nube.

En los *paneles superiores* se anotan los coeficientes de correlación global y por categoría. Por ejemplo, `X1stFlrSF` vs. `SalePrice` tiene una *correlación global* de 0.478, pero dentro de “estandar” es aún mayor (≈0.535) y más moderada en “cara” (≈0.233). `OverallQual` vs. `SalePrice` arroja 0.303 global, con “barata” en 0.274, “estandar” en 0.291 y “cara” en 0.019, reflejando que la fuerza de asociación varía según el segmento de precio. Varias relaciones (p. ej. `YearBuilt` vs. `SalePrice`) son débiles globalmente (≈0.146) y casi nulas en ciertos grupos, lo que señala heterogeneidad en la dinámica de cada categoría.

```{r nearZero_variance}
nzv <- caret::nearZeroVar(train_data, saveMetrics = TRUE)
nzv[nzv$nzv, ]

```
Cada variable marcada con `nzv = TRUE` (por ejemplo `Street`, `PoolArea`, `EnclosedPorch`, `Functional`, etc.) presenta muy poca variabilidad: una proporción altísima de casos en una sola categoría (freqRatio muy elevada) y casi ningún valor único (percentUnique muy bajo). En la práctica, esto significa que esas columnas no aportan separación útil entre clases y pueden introducir ruido o redundancia en el modelo.

Por ello, es recomendable **eliminar** todas las variables con `nzv = TRUE` antes de entrenar la SVM. Con esto reduces la dimensionalidad sin perder información relevante, aceleras el ajuste y evitas posibles problemas de sobreajuste o condicionamiento numérico.

```{r PCA, echo=TRUE}


df_pca <- train_data %>%
  select(all_of(numeric_vars), CategoriaPrecio) %>%
  filter(if_all(all_of(numeric_vars), ~ is.finite(.)))

pca_res <- prcomp(df_pca[, numeric_vars], center = TRUE, scale. = TRUE)

autoplot(pca_res, data = df_pca, colour = "CategoriaPrecio") +
  theme_minimal() +
  labs(
    title = "PCA de Variables Numéricas",
    x     = "Primer Componente Principal (PC1)",
    y     = "Segundo Componente Principal (PC2)"
  )


```
En el diagrama de PCA, las tres categorías muestran un **gradient en el eje horizontal (PC1)**: las casas “cara” (azul) tienden a concentrarse hacia valores negativos de PC1, las “estandar” (verde) orbitan alrededor de cero, y las “barata” (rojo) se desplazan hacia valores positivos. Esto indica que la primera componente principal capta gran parte de la variabilidad asociada al precio, aunque existe un **solapamiento notable** entre categorías, por lo que no se genera una separación perfectamente lineal.

4. Genere varios (más de 2) modelos de SVM con diferentes kernels y distintos valores en los parámetros c, gamma (circular) y d (en caso de que utilice el polinomial). Puede tunear el modelo de forma automática siempre que explique los resultados.
```{r svm, echo=FALSE}


set.seed(42)

train_data$CategoriaPrecio <- factor(
  train_data$CategoriaPrecio,
  levels = c("barata","estandar","cara")
)

dv <- dummyVars(~ ., data = train_data %>% select(-CategoriaPrecio), fullRank = TRUE)
X  <- predict(dv, newdata = train_data) %>% as.data.frame()

pp_imp <- preProcess(X, method = "medianImpute")
X_imp  <- predict(pp_imp, X)

nzv <- nearZeroVar(X_imp)
if(length(nzv) > 0) X_imp <- X_imp[ , -nzv]

corr_mat  <- cor(X_imp)
high_corr <- findCorrelation(corr_mat, cutoff = 0.90)
if(length(high_corr) > 0) X_imp <- X_imp[ , -high_corr]

pp_final <- preProcess(X_imp, method = c("YeoJohnson", "center", "scale"))
X_ready <- predict(pp_final, X_imp)

train_final <- bind_cols(
  X_ready,
  CategoriaPrecio = train_data$CategoriaPrecio
)

ctrl       <- trainControl(
  method          = "cv",
  number          = 5,
  classProbs      = TRUE,
  summaryFunction = multiClassSummary
)
grid_linear <- expand.grid(C = c(0.1, 1, 10))

svm_lin <- train(
  CategoriaPrecio ~ .,
  data      = train_final,
  method    = "svmLinear",
  trControl = ctrl,
  tuneGrid  = grid_linear
)

print(svm_lin)


```
El SVM lineal entrenado sobre las 1 021 observaciones y 96 predictores, evaluado mediante validación cruzada a 5 folds, mostró un claro óptimo con C=10: alcanzó un acurracy promedio de 0.888  un AUC de 0.97 y un Kappa de 0.82. Además mejoró la sensibilidad media a 0.889 Un C intermedio logra el mejor equilibrio entre sesgo y varianza, superando tanto a valores muy pequeños (modelo excesivamente rígido) como a valores muy grandes (modelo susceptible a sobreajuste).


5. Use los modelos para predecir el valor de la variable respuesta. 
6. Haga las matrices de confusión respectivas. 

```{r svm_predict, echo=FALSE}

set.seed(42)

test_data$CategoriaPrecio <- factor(test_data$CategoriaPrecio, levels = c("barata","estandar","cara"))
train_data$CategoriaPrecio <- factor(train_data$CategoriaPrecio, levels = c("barata","estandar","cara"))
train_data$dataset <- "train"
test_data$dataset  <- "test"

cat_cols <- names(train_data)[sapply(train_data, function(x) is.character(x) || is.factor(x)) &
                               !names(train_data) %in% c('CategoriaPrecio','dataset')]
for(col in cat_cols) {
  train_data[[col]][is.na(train_data[[col]])] <- 'None'
  test_data[[col]][is.na(test_data[[col]])]   <- 'None'
  lvls <- unique(train_data[[col]])
  test_data[[col]] <- factor(
    ifelse(test_data[[col]] %in% lvls, as.character(test_data[[col]]), 'None'),
    levels = unique(c(lvls, 'None'))
  )
  train_data[[col]] <- factor(train_data[[col]], levels = levels(test_data[[col]]))
}

df_all <- bind_rows(train_data, test_data)

dv_all <- dummyVars(~ . - Id - dataset - CategoriaPrecio,
                     data = df_all, fullRank = TRUE)
X_all  <- predict(dv_all, newdata = df_all) %>% as.data.frame()

i_train <- which(df_all$dataset == 'train')
X_train <- X_all[i_train, ]
X_test  <- X_all[-i_train, ]
y_train <- train_data$CategoriaPrecio
y_test  <- test_data$CategoriaPrecio

pp_imp      <- preProcess(X_train, method = 'medianImpute')
X_train_imp <- predict(pp_imp, X_train)
X_all_imp   <- predict(pp_imp, X_all)

nzv_cols <- nearZeroVar(X_train_imp)
if(length(nzv_cols) > 0) {
  X_train_imp <- X_train_imp[, -nzv_cols, drop = FALSE]
  X_all_imp   <- X_all_imp[, -nzv_cols, drop = FALSE]
}

corrm     <- cor(X_train_imp)
hc        <- findCorrelation(corrm, cutoff = 0.90)
if(length(hc) > 0) {
  X_train_imp <- X_train_imp[, -hc, drop = FALSE]
  X_all_imp   <- X_all_imp[, -hc, drop = FALSE]
}

pp_final   <- preProcess(X_train_imp, method = c('YeoJohnson','center','scale'))
X_all_pp   <- predict(pp_final, X_all_imp)

X_train_pp <- X_all_pp[i_train, ]
X_test_pp  <- X_all_pp[-i_train, ]

ctrl     <- trainControl(method = 'cv', number = 5, classProbs = TRUE, summaryFunction = multiClassSummary)
grid_lin <- expand.grid(C = c(0.1, 1, 10))
svm_lin   <- train(x = X_train_pp, y = y_train,
                   method = 'svmLinear', trControl = ctrl, tuneGrid = grid_lin)

pred    <- predict(svm_lin, X_test_pp)
results <- data.frame(Id = df_all$Id[-i_train], Actual = y_test, Predicted = pred)
print(head(results))
print(confusionMatrix(pred, y_test))
```
La matriz de confusión revela un desempeño casi impecable: de 139 casas “baratas”, 139 fueron correctamente clasificadas y solo 1 se confundió como “estandar”; de 143 viviendas “estandar”, 143 se acertaron,32 se asignaron a “cara” y 2 a “barata”; y de 148 casas “cara”, 146 fueron bien identificadas y solo 2 pasaron a “estandar”. Las sensibilidades por clase oscilan entre 97.99 % (“cara”) y 98.58 % (“barata”), mientras que la especificidad supera el 98 % en todos los casos, destacando un excelente balance entre verdaderos positivos y negativos. La elevada precisión predictiva (PPV) de 99.29 % para “barata”, 96.62 % para “estandar” y 98.65 % para “cara” confirma que casi todas las predicciones son correctas, y las tasas de prevalencia reflejan que el modelo mantiene fuerte discriminación incluso con distribución de clases equilibrada.

A pesar de que parecen ser resultados alentadores. Una precisión tan alta (0.9817) puede ser signo de sobreajuste, por lo que es importante a tomar en cuenta para evitar confusiones.
