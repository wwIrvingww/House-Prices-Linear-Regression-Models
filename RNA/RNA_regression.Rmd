---
title: "RNA_regression"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(neuralnet)
library(MASS)
library(dplyr)
library(ggplot2)
```

```{r load_data, echo=FALSE}
#train data ya tiene el 70 y test_data el 30%
train_data <- read.csv("../train_final.csv")
test_data <- read.csv("../test_final.csv")
```

9. Seleccione ahora el SalesPrice como variable respuesta.
```{r selection, echo=FALSE}
seleccionar_numericas <- function(data) {
  # Identificar columnas numéricas
  numericas <- sapply(data, is.numeric)
  # Filtrar y eliminar columnas no numéricas
  data_numericas <- data[, numericas]
  # Eliminar columnas con muchos NA 
  data_numericas <- data_numericas[, colSums(is.na(data_numericas)) < nrow(data_numericas) * 0.5]
  return(data_numericas)
}

# Aplicar a train y test
train_numericas <- seleccionar_numericas(train_data)
test_numericas <- seleccionar_numericas(test_data)

# Verificar las variables seleccionadas
names(train_numericas)
names(test_numericas)

```



```{r data_processing, echo=FALSE}

# valores na
preproc <- preProcess(train_numericas, method = c("medianImpute", "center", "scale"))
train_processed <- predict(preproc, train_numericas)
test_processed <- predict(preproc, test_numericas)

# revisar que no hayan na
sum(is.na(train_processed))
sum(is.na(test_processed))
```

10. Genere dos modelos de regresión con redes neuronales con diferentes topologías y
funciones de activación para predecir el precio de las casas.

```{r rna_model1, echo=FALSE}
# Fórmula: todas las variables numéricas excepto "Id" para predecir "SalePrice"
formula <- as.formula(paste("SalePrice ~", 
                           paste(names(train_processed)[!names(train_processed) %in% c("Id", "SalePrice")], 
                           collapse = " + ")))

# Entrenar
set.seed(123)
modelo <- neuralnet(
  formula,
  data = train_processed,
  hidden = c(5, 3),  # Dos capas ocultas con 5 y 3 neuronas
  linear.output = TRUE,  # Para regresión
  act.fct = "logistic",  # Función de activación
  threshold = 0.1  # Umbral de convergencia
)

# Graficar la red
plot(modelo)

```

```{r rna_model1_eval, echo=FALSE}
# Predecir en test_processed (asegúrate de que no tenga "SalePrice")
test_processed_data <- select(test_processed, -c("SalePrice"))
predicciones_test <- predict(modelo, test_processed_data)

# Calcular métricas (RMSE y R²)
rmse <- sqrt(mean((predicciones_test - test_processed$SalePrice)^2))
r2 <- cor(predicciones_test, test_processed$SalePrice)^2

cat("RMSE:", rmse, "\nR²:", r2)

#Obtener los parámetros de normalización de SalePrice
media_saleprice <- mean(train_data$SalePrice)
sd_saleprice <- sd(train_data$SalePrice)

# Desnormalizar las predicciones y los valores reales
predicciones_dolares <- predicciones_test * sd_saleprice + media_saleprice
real_dolares <- test_processed$SalePrice * sd_saleprice + media_saleprice

#Calcular RMSE en dólares
rmse_dolares <- sqrt(mean((predicciones_dolares - real_dolares)^2))
cat("\nRMSE en dólares:", rmse_dolares)

```

El modelo que implementamos utiliza una red neuronal con dos capas ocultas. Tiene 5 neuronas en la primera capa y 3 en la segunda. Esta configurada para regresión para poder predecir sobre el precio de las casas y elegimos la función de activación logística porque, aunque es común en clasificación, también puede funcionar en regresión cuando los datos están normalizados. Con el parámetro linear.output = TRUE asegure la naturaleza lineal de la predicción, algo muy imoprtant para hacer modelos de regresión. utilizando redes.  Además, colocamos un umbral de convergencia de 0.1 para detener el entrenamiento si la reducción del error es mínim. Esto es importante también ya que puede ayudarnos a reducir sobreajuste.

Los resultados muestran un R² de 0.793. Esto quiere decir que el modeloexplica casi el 80% de la variabilidad en los precios. Esto es un desempeño considerado bueno para el primer intento. Sin embargo, el RMSE en dólares de casi 39k dólares, indica que hay una desviación considerable del valor real. Si bien esto es mejor que un modelo aleatorio, sigue siendo un margen alto para decisiones financieras críticas. No obstante, es importante menconar que este número puede ser considerado válido, dada la gran variedad de datos y precios distintos en el set de datos. En comparación con otros enfoques, como regresión lineal o árboles de decisión, esta red neuronal captura relaciones no lineales en los datos, pero podría optimizarse aún más.

```{r rna_model2, echo=FALSE}
# Fórmula: todas las variables numéricas excepto "Id" para predecir "SalePrice"
formula <- as.formula(paste("SalePrice ~", 
                           paste(names(train_processed)[!names(train_processed) %in% c("Id", "SalePrice")], 
                           collapse = " + ")))

# Entrenar
# Modelo 2 tunin manual :o
set.seed(123)
modelo2 <- neuralnet(
  formula,
  data = train_processed,
  hidden = c(5, 2),       # cambio en las neuronas
  linear.output = TRUE,
  act.fct = "tanh",       # otra act func
  threshold = 0.05,       # mas estricto
)

# Graficar la red
plot(modelo2)

```

```{r rna_model1_eval, echo=FALSE}
# Predecir en test_processed (asegúrate de que no tenga "SalePrice")
test_processed_data <- select(test_processed, -c("SalePrice"))
predicciones_test <- predict(modelo2, test_processed_data)

# Calcular métricas (RMSE y R²)
rmse <- sqrt(mean((predicciones_test - test_processed$SalePrice)^2))
r2 <- cor(predicciones_test, test_processed$SalePrice)^2

cat("RMSE:", rmse, "\nR²:", r2)

#Obtener los parámetros de normalización de SalePrice
media_saleprice <- mean(train_data$SalePrice)
sd_saleprice <- sd(train_data$SalePrice)

# Desnormalizar las predicciones y los valores reales
predicciones_dolares <- predicciones_test * sd_saleprice + media_saleprice
real_dolares <- test_processed$SalePrice * sd_saleprice + media_saleprice

#Calcular RMSE en dólares
rmse_dolares <- sqrt(mean((predicciones_dolares - real_dolares)^2))
cat("\nRMSE en dólares:", rmse_dolares)

```

El modelo que implementamos en esta segunda versión sigue utilizando una red neuronal con dos capas ocultas, pero ahora con 5 neuronas en la primera capa y 2 en la segunda, una configuración ligeramente más compacta que la anterior. Optamos por la función de activación tangente hiperbólica, tanh, que, a diferencia de la logística usada antes, trabaja mejor con datos normalizados al tener un rango de salida entre -1 y 1. Esto puede ayudar a que el aprendizaje sea más eficiente, especialmente cuando los datos tienen una distribución simétrica alrededor de cero.

Mantuvimos linear.output = TRUE para asegurar que la salida del modelo fuera lineal, ya que la variable respuest es continua. Además, redujimos el umbral de convergencia a 0.05, lo que hace que el entrenamiento sea más exigente, deteniéndose solo cuando los ajustes en los pesos de la red sean mínimos. Este cambio busca reducir el rmse prácticamente. 

Los resultados obtenidos son interesantes. El R² de 0.844 nos indica que el modelo explica aproximadamente el 84.5% de la variabilidad en los precios, una mejora bastante buena. Esto sugiere que los cambios en la arquitectura y la función de activación están capturando mejor las relaciones en los datos aunque estemso usando menos neouronas. El RMSE en dólares se redujo a alrededor de 31,466, lo que significa que, en promedio, las predicciones se desvían en poco más de 31k dólares del valor real.

Si bien sigue siendo un margen de error considerable hay que nuevamente tener en cuenta que los precios de las casas pueden variar bastante. Un error de esta magnitud puede ser aceptable dependiendo de la situación y el resultado ya está en un rango bastante menor que el modelo anterior.

11. Compare los dos modelos de regresión y determine cuál funcionó mejor para predecir el precio de las casas.

Habiendo terminado estos 2 modelos se puede ver que el segundo tuvo un mejor desempeño en todas las métricas clave. El primer modelo con 5 neuronas en la primera capa y 3 en la segunda, junto con la función de activación logística, logró un R² de 0.793. Habíamos dicho que ya era un resultado decente, ya que el modelo explica cerca del 80% de la variabilidad en los precios. Sin embargo, su RMSE en dólares de aproximadamente 38,700 indicaba que en promedio, las predicciones se desviaban del valor real. Este es un margen de error que dejó campo para poder introducir mejoras. Dichas mejoras fueron encontradas, por medio de un tuning manual, probando distintas configuraciones y también cambiando la función de activación.

En el segundo modelo, redujimos la segunda capa a solo 2 neuronas y cambiamos la función de activación a tangente hiperbólica (tanh). Con estos ajustes, junto con un umbral de convergencia más estricto de 0.05, se obtuvieron resultados más precisos. Ya que ahora se tiene un R² de 0.845, casi un 5% más alto que el primer modelo. También, un RMSE de 31k dólares. Esto significa que, en promedio, las predicciones ahora se acercan más a los valores reales. La desviación es casi 7k dólares menos que antes.

Al final, el segundo modelo no solo explica mejor cómo varían los precios de las casas, sino que también comete errores más pequeños en sus estimaciones. Los cambios que introdujimos, especialmente el uso de tanh y una arquitectura ligeramente más ajustada, ayudaron a capturar mejor las relaciones en los datos sin la necesidad de aumentar la complejidad de la red neuronal, pudiendo haber agregado mas neuronas o repeticiones en el entrenamiento. Ahora lo que nos queda ver es si con estos modelos, debido a las mejoras, no se llego a alcanzar algún tipo de sobre ajuste por la mejora del rendimiento. 

12. Analice si no hay sobreajuste en los modelos. Use para esto la curva de aprendizaje.

```{r overfit_analisis_model1, echo=FALSE}
set.seed(123)
train_sizes <- seq(0.1, 1.0, by = 0.1)

train_rmse <- numeric(length(train_sizes))
test_rmse <- numeric(length(train_sizes))

for(i in seq_along(train_sizes)) {
  pct <- train_sizes[i]
  n_subset <- floor(pct * nrow(train_processed))
  subset_idx <- sample(1:nrow(train_processed), size = n_subset)
  
  # Entrenar el modelo con el subset
  modelo_subset <- neuralnet(
    formula,
    data = train_processed[subset_idx, ],
    hidden = c(5, 3),
    linear.output = TRUE,
    act.fct = "logistic",
    threshold = 0.1
  )
  
  # Predecir en el conjunto de entrenamiento (subset)
  train_pred <- predict(modelo_subset, train_processed[subset_idx, ])
  train_rmse[i] <- sqrt(mean((train_pred - train_processed$SalePrice[subset_idx])^2))
  
  # Predecir en el conjunto de prueba (test_processed)
  test_pred <- predict(modelo_subset, select(test_processed, -SalePrice))
  test_rmse[i] <- sqrt(mean((test_pred - test_processed$SalePrice)^2))
}

learning_data <- data.frame(
  TrainingSize = train_sizes * 100,
  TrainRMSE = train_rmse,
  TestRMSE = test_rmse
)

ggplot(learning_data, aes(x = TrainingSize)) +
  geom_line(aes(y = TrainRMSE, color = "Entrenamiento"), size = 1) +
  geom_line(aes(y = TestRMSE, color = "Prueba"), size = 1) +
  labs(title = "Curvas de Aprendizaje - Red Neuronal",
       x = "Porcentaje de Datos de Entrenamiento",
       y = "RMSE",
       color = "Conjunto") +
  scale_color_manual(values = c("Entrenamiento" = "blue", "Prueba" = "red")) +
  theme_minimal()

```

En este primer modelo podemos ver que tanto el learning del entrenamiento como el de prueba van cambiando con respecto al porcentaje de datos. En el caso de los datos de prueba podemos ver que ha medida que pasa el tiempo se va disminuyendo el rmse. En el caso del entrenamiento el rmse va ligeramente en aumento. Esto no implica que el modelo esté empeorando, como son los datos de prueba, esto quiere decir que el modelo va generalizando la información y por ende aumenta el rmse, si se mantuviera siempre baja significaría que hay sobreajuste y el error se mantuvo bajo todo el tiempo. Algo interesante es que a pesar de que ambas gráficas parecía que llegarían a juntarse, al acercarse al 100% de los datos, volvieron a separarse. Esta gráfica es un poco dificil de intrepretar ya que los leearning rates variaron un poco. Al final el modelo parece que si generaliza bien hasta cierto punto, pero el echo que la distancia entre ambos se agrandó al final, puede dar indicios de sobreajuste. Puede que no sea tanto, pero si puede que haya un poco en el modelo. 


```{r overfit_analisis_model1, echo=FALSE}
set.seed(123)  
train_sizes_modelo2 <- seq(0.1, 1.0, by = 0.1)  
train_rmse_modelo2 <- numeric(length(train_sizes_modelo2))
test_rmse_modelo2 <- numeric(length(train_sizes_modelo2))

for (i in seq_along(train_sizes_modelo2)) {
  pct_modelo2 <- train_sizes_modelo2[i]
  n_subset_modelo2 <- floor(pct_modelo2 * nrow(train_processed))
  subset_idx_modelo2 <- sample(1:nrow(train_processed), size = n_subset_modelo2)
  
  modelo2_subset <- neuralnet(
    formula,
    data = train_processed[subset_idx_modelo2, ],
    hidden = c(5, 2),
    linear.output = TRUE,
    act.fct = "tanh",
    threshold = 0.05
  )
  
  # Solo si el modelo tiene pesos (checa si convergió)
  if (!is.null(modelo2_subset$result.matrix)) {
    train_pred_modelo2 <- predict(modelo2_subset, train_processed[subset_idx_modelo2, ])
    train_rmse_modelo2[i] <- sqrt(mean((train_pred_modelo2 - train_processed$SalePrice[subset_idx_modelo2])^2))
    
    test_pred_modelo2 <- predict(modelo2_subset, select(test_processed, -SalePrice))
    test_rmse_modelo2[i] <- sqrt(mean((test_pred_modelo2 - test_processed$SalePrice)^2))
  } else {
    # Si no converge, asigna NA o un valor alto para marcarlo
    train_rmse_modelo2[i] <- NA
    test_rmse_modelo2[i] <- NA
    cat("Modelo no convergió para porcentaje:", pct_modelo2 * 100, "%\n")
  }
}

# Crear dataframe para graficar
learning_data_modelo2 <- data.frame(
  TrainingSize = train_sizes_modelo2 * 100,
  TrainRMSE = train_rmse_modelo2,
  TestRMSE = test_rmse_modelo2
)

ggplot(learning_data_modelo2, aes(x = TrainingSize)) +
  geom_line(aes(y = TrainRMSE, color = "Entrenamiento (Modelo 2)"), size = 1) +
  geom_line(aes(y = TestRMSE, color = "Prueba (Modelo 2)"), size = 1) +
  labs(
    title = "Curvas de Aprendizaje - Modelo 2 (2 capas, tanh)",
    x = "Porcentaje de Datos de Entrenamiento",
    y = "RMSE",
    color = "Conjunto"
  ) +
  scale_color_manual(values = c("Entrenamiento (Modelo 2)" = "darkblue", "Prueba (Modelo 2)" = "darkred")) +
  theme_minimal()

```

Ahora en el modelo 2, donde se fue más estricto con las metricas se obtuvieron mejores resultados, pero al momento de hacer la gráfica para el learning rate, hubieron algunos problemas.Específicamente al llegar al 50% de los datos y al 100% de los datos el modelo no convergio. Creemos que esto pasó porque la red neuronal en algún punto, con algunos porcentajes en específico, no era capaz de converger al ser muy estricto. Lo interesante es que ese error nunca ocurrió cuando se entrenó el modelo sin ver el learning rate.

Viendo la gráfica se puede ver que ambos modelos llegan a juntarse bastante al final, lo cuál en general es un muy buen indicio. Pero el problema es que si observamos bien la linea azul, el modelo casi nunca empeoró o aumento su rmse. La linea de entrenamiento, aunque bien se redujo considerablemente a lo largo de la gráfica, la linea azul se mantuve en el mismo rmse casi todo el tiempo. Esto es un indicador claro de sobre ajuste. Aunque la distancia entre el desempeño entre ambos sea reducida, hay sobreajuste ya que con los datos de entrenamiento, no aumentó el rmse, osea que seguraemnte el modelo tendrá problemas para generalizar y predecir con datos que no conozca. Además el hecho que no converga con algunos porcentajes puede que genere problemas con sets de datos específicos.


13. Para el modelo elegido de regresión tunee los parámetros y discuta si puede mejorar
todavía el modelo sin llegar a sobre ajustarlo. 


