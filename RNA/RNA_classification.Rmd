---
title: "RNA_classification"
author: "Irving, Chuy"
date: "2025-04-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(nnet)
```

1. Use los mismos conjuntos de entrenamiento y prueba que utilizó en las entregas anteriores
```{r load_data, echo=FALSE}
#train data ya tiene el 70 y test_data el 30%
train_data <- read.csv("../train_final.csv")
test_data <- read.csv("../test_final.csv")
```

```{r remove_na_columns, echo=FALSE}
pct_na <- sapply(train_data, function(x) mean(is.na(x))*100)
drop_cols <- names(pct_na[pct_na > 75])
train_data <- train_data %>% select(-all_of(drop_cols))
test_data  <- test_data  %>% select(-all_of(drop_cols))
```
Se removieron las columnas problematicas. Se remueven las columnas que no dan información útil.

2. Seleccione como variable respuesta la que creó con las categorías del precio de la casa.
```{r discretization, echo=FALSE}
breaks <- quantile(train_data$SalePrice, probs = c(0,1/3,2/3,1), na.rm=TRUE)
labels <- c("barata","estandar","cara")

train_data$CategoriaPrecio <- cut(train_data$SalePrice, breaks=breaks, labels=labels, include.lowest=TRUE)
test_data$CategoriaPrecio  <- cut(test_data$SalePrice,  breaks=breaks, labels=labels, include.lowest=TRUE)

```
Creamos las tres categorías de las casas (barata, estándar, cara.)

3. Genere dos modelos de redes neuronales que sean capaz de clasificar usando la variable respuesta que categoriza las casas en baratas, medias y caras. Estos modelos deben tener diferentes topologías y funciones de activación.
```{r pipeline_prepareData, include=FALSE}

# — 1. Alinear niveles de factores y NA —
for(col in names(train_data)) {
  if(is.character(train_data[[col]]) || is.factor(train_data[[col]])) {
    # Convertir a caracter y manejar NAs
    train_data[[col]] <- as.character(train_data[[col]])
    test_data[[col]] <- as.character(test_data[[col]])
    train_data[[col]][is.na(train_data[[col]])] <- "None"
    test_data[[col]][is.na(test_data[[col]])] <- "None"
    
    # Obtener todos los niveles únicos
    all_levels <- unique(c(train_data[[col]], test_data[[col]]))
    
    # Convertir a factor con niveles únicos
    train_data[[col]] <- factor(train_data[[col]], levels = all_levels)
    test_data[[col]] <- factor(test_data[[col]], levels = all_levels)
  }
}
# — 2. Marcar la respuesta y dataset —
train_data$CategoriaPrecio <- factor(train_data$CategoriaPrecio,
                                     levels = c("barata","estandar","cara"))
train_data$dataset <- "train"
test_data$dataset  <- "test"

# — 3. Unir para dummies coherentes —
df_all <- bind_rows(train_data, test_data)

# — 4. Eliminar constantes antes de dummyVars —
n_uniq <- sapply(df_all, function(x) length(unique(x)))
df_all <- df_all[, n_uniq > 1]


# — 5. Crear dummies (excluyendo Id, dataset y la respuesta) —

dv_all <- dummyVars(~ . - Id - dataset - CategoriaPrecio,
                    data = df_all, fullRank = TRUE)
X_all  <- predict(dv_all, newdata = df_all) %>% as.data.frame()

# — 6. Imputar medianas en train, luego aplicar a todo —
i_train     <- which(df_all$dataset == "train")
X_train_raw <- X_all[i_train, ]
pp_imp      <- preProcess(X_train_raw, method = "medianImpute")
X_all_imp   <- predict(pp_imp, X_all)

# — 7. Eliminar near-zero variance según train —
nzv_cols <- nearZeroVar(X_all_imp[i_train, , drop=FALSE])
if(length(nzv_cols) > 0) {
  X_all_imp <- X_all_imp[ , -nzv_cols, drop=FALSE]
}

# — 8. Quitar alta correlación (>0.90) según train —
corr_m   <- cor(X_all_imp[i_train, ])
high_corr <- findCorrelation(corr_m, cutoff = 0.90)
if(length(high_corr) > 0) {
  X_all_imp <- X_all_imp[ , -high_corr, drop=FALSE]
}

# — 9. Yeo-Johnson + center + scale según train —
pp_final  <- preProcess(X_all_imp[i_train, ],
                       method = c("YeoJohnson","center","scale"))
X_all_pp  <- predict(pp_final, X_all_imp)

# — 10. Separar de nuevo train/test y respuesta —
X_train_pp <- X_all_pp[i_train, ]
X_test_pp  <- X_all_pp[-i_train, ]
y_train    <- train_data$CategoriaPrecio
y_test     <- test_data$CategoriaPrecio

```

```{r check, include=FALSE}
# Verificar dimensiones
cat("Dimensiones train:", dim(X_train_pp), "\n")
cat("Dimensiones test:", dim(X_test_pp), "\n")

# Verificar que no haya NA
cat("NAs en train:", sum(is.na(X_train_pp)), "\n")
cat("NAs en test:", sum(is.na(X_test_pp)), "\n")

# Verificar balance de clases
table(y_train)
```
```{r second_check, include=FALSE}
# Identificar y eliminar columnas con varianza práctica cero
library(caret)

# Primero, asegurarnos de que todas las variables son numéricas
train_df <- data.frame(X_train_pp)
test_df <- data.frame(X_test_pp)

# Función para detectar columnas con >95% de un solo valor
find_constant_cols <- function(df) {
  constant_cols <- sapply(df, function(x) {
    if(is.numeric(x)) {
      max_prop <- max(table(x)/length(x))
      max_prop > 0.95
    } else {
      FALSE
    }
  })
  names(df)[constant_cols]
}

constant_cols <- find_constant_cols(train_df)
if(length(constant_cols) > 0) {
  train_df <- train_df[, !names(train_df) %in% constant_cols]
  test_df <- test_df[, !names(test_df) %in% constant_cols]
}

# Añadir la variable respuesta
train_df$CategoriaPrecio <- y_train
test_df$CategoriaPrecio <- y_test

# Verificar estructura final
str(train_df[, 1:5])
cat("\nColumnas eliminadas:", constant_cols)

# Verificar estructura
str(train_df[, 1:5])  # Mostrar primeras columnas

# Verificar columnas con un solo nivel
sapply(train_df, function(x) length(unique(x)))

# Eliminar manualmente si es necesario
train_df <- train_df[, !sapply(train_df, function(x) length(unique(x)) == 1)]
```


4. Use los modelos para predecir el valor de la variable respuesta.
5. Haga las matrices de confusion respectivas.
6. Compare los resultados obtenidos con los diferentes modelos de clasificación usando redes neuronales en cuanto a efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivocó más, menos y la importancia que tienen los errores.)

#Primer modelo de Red Neuronal
```{r first_model, echo=FALSE}

# 1. Preparar fórmula y datos
predictores <- names(train_df)[!names(train_df) %in% c("CategoriaPrecio")]
formula_nnet <- as.formula(paste("CategoriaPrecio ~", paste(predictores, collapse = " + ")))

# 2. Configurar parámetros del modelo
set.seed(123)
modelo_nnet <- nnet(
  formula = formula_nnet,
  data = train_df,
  size = 10,          # Neuronas en capa oculta
  decay = 0.05,       # Parámetro de regularización
  maxit = 500,        # Número máximo de iteraciones
  MaxNWts = 5000,     # Máximo número de pesos
  trace = TRUE,       # Mostrar progreso
  # Configuración específica para clasificación multiclase:
  entropy = FALSE,    # Usar softmax (no entropía cruzada)
  censored = FALSE,
  skip = FALSE,
  rang = 0.1,         # Rango inicial de pesos aleatorios
  Hess = FALSE
)

# 1. Predecir probabilidades y elegir la clase con mayor probabilidad
probs   <- predict(modelo_nnet, newdata = test_df, type = "raw")
pred_vec <- apply(probs, 1, function(x) names(x)[which.max(x)])

# 2. Crear factores con los mismos niveles que la variable real
true_fac <- factor(test_df$CategoriaPrecio,
                   levels = levels(test_df$CategoriaPrecio))
pred_fac <- factor(pred_vec,
                   levels = levels(true_fac))

# 3. Eliminar casos NA/“None” si corresponde
nas <- is.na(true_fac) | true_fac == "None"
if (any(nas)) {
  cat(sum(nas), "caso(s) con etiqueta ausente eliminado(s).\n")
  true_fac <- true_fac[!nas]
  pred_fac <- pred_fac[!nas]
}

# 4. Quitar niveles sin observaciones
true_fac <- droplevels(true_fac)
pred_fac <- droplevels(pred_fac)

# 5. Cálculo de la matriz de confusión
cm_obj <- caret::confusionMatrix(pred_fac, true_fac)
print(cm_obj)

# 6. Precisión global
cat("Precisión global:", round(cm_obj$overall["Accuracy"], 4), "\n")

# 7. Heatmap de la matriz de confusión
cm_df <- as.data.frame(cm_obj$table)
colnames(cm_df) <- c("Real", "Predicho", "Freq")

ggplot(cm_df, aes(x = Predicho, y = Real, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 4) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matriz de Confusión", x = "Predicción", y = "Etiqueta Real") +
  theme_minimal()


```
Se realizó un modelo de red Neuronal utilizando la función nnet de la librería de nnet supervisada de una sola capa oculta para una tarea de clasificación multiclase (predecir "CategoriaPrecio" a partir de varias variables predictoras). Los parametros utilizados son los siguientes: Se utilizó un size de 10 para el número de neuronas en la capa oculta; un decay de 0.05 para prevenir overfitting, un máximo de 500 iteraciones, un límite superior de 5000 del número de pesos.  

Los resultados son bastante optimistas. Se alcanzó un accuracy de 0.8876 (con un intervalo de confianza del 95% entre 0.8542 y 0.9157), un número aceptable que no roza el overfitting, también tenemos un kappa de 0.8314, un nivel muy bueno que indica una fuerte concordancia más allá del azar. Con respecto de la matriz de confusión, observamos que el modelo es más susceptible a la clase barata (con 130 aciertos de 141 posibles) y menos a la clase estandar (117 correctas de 146), donde se concentran la mayoría de los errores.

Detallando más se puede decir que la clase cara muestra el mejor desempeño con 140 aciertos de 149 (94% sensibilidad). Existe cierta confusión entre estandar y barata (16 errores) y entre estandar y cara (13 errores). Las precisiones por clase son consistentes: 91.5% para cara, 89% para barata y 85.4% para estandar Los valores predictivos negativos superan el 90% en todas las categorías, indicando buena capacidad para descartar clases.





#Segundo modelo de Red Neuronal
```{r}
# Recodifica las categorías como numéricas temporalmente
train_df$CategoriaPrecio_num <- as.numeric(factor(train_df$CategoriaPrecio, levels = niveles_conf))
test_df$CategoriaPrecio_num <- as.numeric(factor(test_df$CategoriaPrecio, levels = niveles_conf))

# Verifica la codificación
table(train_df$CategoriaPrecio, train_df$CategoriaPrecio_num)
```
```{r}
library(nnet)
library(caret)

# 1. DIAGNÓSTICO ----------------------------------------------------------
cat("\n=== DIAGNÓSTICO INICIAL ===\n")

# Verificar distribución de clases
cat("\nDistribución de clases en entrenamiento:\n")
train_dist <- table(train_df$CategoriaPrecio)
print(train_dist)
cat("Proporciones:", round(prop.table(train_dist), 3), "\n\n")

# Verificar distribución en test
cat("Distribución en test:\n")
test_dist <- table(test_df$CategoriaPrecio)
print(test_dist)
cat("\n")

# Verificar estructura de datos
cat("Estructura de los datos:\n")
str(train_df[, c("CategoriaPrecio", head(setdiff(names(train_df), "CategoriaPrecio"), 3))])

# 2. CORRECCIÓN INMEDIATA -------------------------------------------------
cat("\n=== CORRECCIÓN MANUAL ===\n")

# Inversión de categorías (solución temporal)
pred_vec_corregido <- ifelse(pred_vec_alt == "cara", "barata",
                            ifelse(pred_vec_alt == "barata", "cara", 
                                  "estandar"))

# Matriz de confusión corregida
cat("\nMatriz de confusión corregida:\n")
cm_corregido <- confusionMatrix(
  factor(pred_vec_corregido, levels = niveles_conf),
  factor(test_df$CategoriaPrecio, levels = niveles_conf)
)
print(cm_corregido)

# 3. REENTRENAMIENTO MEJORADO --------------------------------------------
cat("\n=== REENTRENAMIENTO DEL MODELO ===\n")

set.seed(321)
modelo_mejorado <- nnet(
  formula = CategoriaPrecio ~ .,
  data = train_df,
  size = 15,
  decay = 0.05,
  maxit = 500,
  MaxNWts = 10000,
  trace = TRUE,
  entropy = TRUE,
  skip = TRUE,
  # Parámetros adicionales para mejorar convergencia
  rang = 0.1,
  abstol = 1.0e-8,
  reltol = 1.0e-8
)

# Evaluación del nuevo modelo
cat("\nEvaluación del modelo mejorado:\n")
pred_mejorada <- predict(modelo_mejorado, newdata = test_df, type = "class")
cm_mejorada <- confusionMatrix(
  factor(pred_mejorada, levels = niveles_conf),
  factor(test_df$CategoriaPrecio, levels = niveles_conf)
)
print(cm_mejorada)

# Guardar modelo
saveRDS(modelo_mejorado, "modelo_mejorado.rds")
cat("\nModelo guardado como 'modelo_mejorado.rds'\n")

# VISUALIZACIÓN COMPARATIVA ----------------------------------------------
cat("\n=== RESUMEN COMPARATIVO ===\n")

# Crear tabla comparativa
resultados <- data.frame(
  Modelo = c("Original", "Corregido", "Mejorado"),
  Accuracy = c(
    round(mean(pred_vec_alt == test_df$CategoriaPrecio, na.rm = TRUE), 4),
    round(cm_corregido$overall["Accuracy"], 4),
    round(cm_mejorada$overall["Accuracy"], 4)
  ),
  Kappa = c(
    NA,
    round(cm_corregido$overall["Kappa"], 4),
    round(cm_mejorada$overall["Kappa"], 4)
  )
)

print(resultados)

# 7. HEATMAP DE MATRIZ DE CONFUSIÓN --------------------------------------
cat("\n=== VISUALIZACIÓN DE MATRIZ DE CONFUSIÓN ===\n")

# Convertir a dataframe para ggplot
cm_df <- as.data.frame(cm_mejorada$table)
colnames(cm_df) <- c("Real", "Predicho", "Frecuencia")

# Crear el heatmap
heatmap_confusion <- ggplot(cm_df, aes(x = Predicho, y = Real, fill = Frecuencia)) +
  geom_tile(color = "white", linewidth = 0.8) +  # Celdas con bordes blancos
  geom_text(aes(label = Frecuencia), size = 5, color = "black") +  # Texto en negro
  scale_fill_gradient(
    low = "white", 
    high = "#2b8cbe",  # Azul más moderno
    limits = c(0, max(cm_df$Frecuencia))  # Mismo rango para todas las celdas
  ) +
  labs(
    title = "Matriz de Confusión - Modelo Mejorado",
    subtitle = paste("Precisión:", round(cm_mejorada$overall["Accuracy"], 3)),
    x = "Predicción del Modelo",
    y = "Valor Real",
    fill = "Casos"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5),
    panel.grid = element_blank(),
    legend.position = "right"
  ) +
  coord_fixed()  # Para celdas cuadradas

# Mostrar el gráfico
print(heatmap_confusion)

# Guardar el gráfico (opcional)
ggsave("heatmap_confusion.png", plot = heatmap_confusion, width = 8, height = 6, dpi = 300)
cat("\nHeatmap guardado como 'heatmap_confusion.png'\n")
```
Se realizó un segundo modelo neuronal utilizando nuevamente la función nnet de la librería del mismo nombre, manteniendo la arquitectura de red supervisada con una sola capa oculta para la clasificación multiclase de "CategoriaPrecio". Los parámetros clave de este modelo mejorado fueron: un tamaño (size) de 15 neuronas en la capa oculta (aumentando las 10 originales), un decay de 0.05 para controlar el sobreajuste, un máximo de 500 iteraciones y un límite superior de 10,000 pesos.  

Los resultados obtenidos son notablemente altos, mostrando un accuracy de 0.9954 y un kappa de 0.9931, lo que aparentemente indica un rendimiento casi perfecto. Sin embargo, estos excelentes resultados podrían ser indicio de posible overfitting tomadno en cuenta que el modelo no comete prácticamente errores (solo 2 en 436 predicciones) y todas las métricas por clase superan el 98.6% de efectivida.  

La matriz de confusión muestra un comportamiento casi perfecto, pero esta perfección podría sugerir que el modelo ha "memorizado" los patrones en lugar de aprender características generalizables. Es particularmente sospechoso que la clase "estándar", que presentaba dificultades en el modelo anterior, ahora tenga un 100% de aciertos.

#Sobreajuste
7. Analice si no hay sobreajuste en los modelos
#Tuneando parametros
8. Para el modelo elegido de claisifcacion tunee los parametros y discuta si puede mejorar todavía el modelo sin llegar a sobreaustarlo.
